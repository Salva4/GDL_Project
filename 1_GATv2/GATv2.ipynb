{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GATv2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install spektral"
      ],
      "metadata": {
        "id": "kvh-dGR7Voqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import backend as K\n",
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "F4oFHnuuTxzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import Dropout, Input\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.random import set_seed\n",
        "\n",
        "from spektral.data.loaders import SingleLoader\n",
        "from spektral.datasets.citation import Citation\n",
        "from spektral.layers import GATConv\n",
        "from spektral.transforms import LayerPreprocess\n"
      ],
      "metadata": {
        "id": "Bqrt5FG2pg-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
      ],
      "metadata": {
        "id": "FPcCcHuSPUX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spektral.data.graph as gg\n",
        "from scipy import sparse"
      ],
      "metadata": {
        "id": "kU_fFwLW9W7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import itertools\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class DictionaryLookupDataset(object):\n",
        "    def __init__(self, size):\n",
        "        super().__init__()\n",
        "        self.size = size\n",
        "        self.edges, self.empty_id = self.init_edges()\n",
        "      \n",
        "    def init_edges(self):\n",
        "        targets = range(0, self.size)\n",
        "        sources = range(self.size, self.size * 2)\n",
        "        next_unused_id = self.size\n",
        "        all_pairs = itertools.product(sources, targets)\n",
        "        edges = [list(i) for i in zip(*all_pairs)]\n",
        "\n",
        "        return edges, next_unused_id\n",
        "\n",
        "    def create_empty_graph(self, add_self_loops=False):\n",
        "      edge_index = np.array(self.edges, dtype=np.long)\n",
        "      return edge_index\n",
        "    \n",
        "    def get_combinations(self):\n",
        "      # returns: an iterable of [permutation(size)]\n",
        "      # number of combinations: size!\n",
        "      max_examples = 32000 # starting to affect from size=8, because 8!==40320\n",
        "      if math.factorial(self.size) > max_examples:\n",
        "        permutations = [np.random.permutation(range(self.size)) for _ in range(max_examples)]\n",
        "      else:\n",
        "        permutations = itertools.permutations(range(self.size))\n",
        "        \n",
        "      return permutations\n",
        "    \n",
        "    def generate_data(self, train_fraction, unseen_combs):\n",
        "      data_list = []\n",
        "      for perm in self.get_combinations():\n",
        "        edge_index = self.create_empty_graph(add_self_loops=False)\n",
        "        edge_index = sparse.csr_matrix((np.ones(self.size*self.size),(edge_index[0],edge_index[1])),shape=(self.size*2,self.size*2))\n",
        "        nodes = np.array(self.get_nodes_features(perm),dtype=np.long)\n",
        "        target_mask =  np.array([True] * (self.size) + [False] * self.size, dtype=np.bool)\n",
        "        labels = np.array(perm, dtype=np.long)\n",
        "        \n",
        "        data_list.append(gg.Graph(x=nodes, a=edge_index, target_mask=target_mask, y=labels))\n",
        "\n",
        "      dim0, out_dim = self.get_dims()\n",
        "      if unseen_combs:\n",
        "        X_train, X_test = self.unseen_combs_train_test_split(data_list, train_fraction=train_fraction, shuffle=True)\n",
        "      else:\n",
        "        X_train, X_test = train_test_split(data_list, train_size=train_fraction, shuffle=True)\n",
        "\n",
        "      return X_train, X_test, dim0, out_dim\n",
        "\n",
        "    def get_nodes_features(self, perm):\n",
        "      # perm: a list of indices\n",
        "      #Node features is basically {[(A,_),(B,_),...(D,_)] , [(A,1),(B,2),...(D,4)]}.\n",
        "      #Then what is nodes,5,6,7,8,9? These are node numberings. there exists 2k=10 nodes and each have features i.e. a 2-tuple.\n",
        "      # The first row contains (key, empty_id)\n",
        "      # The second row contains (key, value) where the order of values is according to perm\n",
        "      nodes = [(key, self.empty_id) for key in range(self.size)]\n",
        "      for key, val in zip(range(self.size), perm):\n",
        "        nodes.append((key, val))\n",
        "\n",
        "      return nodes\n",
        "\n",
        "    def get_dims(self):\n",
        "      # get input and output dims\n",
        "      in_dim = self.size + 1\n",
        "      out_dim = self.size\n",
        "      return in_dim, out_dim\n",
        "\n",
        "    def unseen_combs_train_test_split(self, data_list, train_fraction, shuffle=True):\n",
        "      per_position_fraction = train_fraction ** (1 / self.size)\n",
        "      num_training_pairs = int(per_position_fraction * (self.size ** 2))\n",
        "      allowed_positions = set(random.sample(list(itertools.product(range(self.size), range(self.size))), num_training_pairs))\n",
        "      train = []\n",
        "      test = []\n",
        "        \n",
        "      for example in data_list:\n",
        "        if all([(i, label.item()) in allowed_positions for i, label in enumerate(example.y)]):\n",
        "          train.append(example)\n",
        "        else:\n",
        "          test.append(example)\n",
        "        \n",
        "        if shuffle:\n",
        "            random.shuffle(train)\n",
        "      return train, test\n"
      ],
      "metadata": {
        "id": "z1sv3JvAxYtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nodes_num = 5\n",
        "dictionary = DictionaryLookupDataset(nodes_num)"
      ],
      "metadata": {
        "id": "jsKteCF2vClK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary.get_dims()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9-OM-D8_bDD",
        "outputId": "157b48d9-31cd-4c21-8c0e-016dc8ee38e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For k=5"
      ],
      "metadata": {
        "id": "qamI0SW7-2vQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, dim0, out_dim = dictionary.generate_data(0.75,False)\n",
        "mean_divisor = 90\n",
        "update = 30"
      ],
      "metadata": {
        "id": "BKx4ACay6THF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0eb2bf65-7153-4954-c1f7-a1ff061cfa67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:41: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For k=4. Dont run if above has been chosen"
      ],
      "metadata": {
        "id": "nEyTeBS6-5mc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, dim0, out_dim = dictionary.generate_data(0.85,False)\n",
        "mean_divisor = 20\n",
        "update = 5"
      ],
      "metadata": {
        "id": "MnzAwceY-1pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spektral.data import Dataset"
      ],
      "metadata": {
        "id": "JsSPNVIXTwiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    \"\"\"\n",
        "    A dataset of five random graphs.\n",
        "    \"\"\"\n",
        "    def __init__(self, list_g, **kwargs):\n",
        "        self.list_g = list_g\n",
        "\n",
        "        super().__init__(**kwargs)\n",
        "    \n",
        "    def read(self):\n",
        "      return self.list_g"
      ],
      "metadata": {
        "id": "Ct6T29_LZ9pK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "md1 = MyDataset(X_train)\n",
        "md2 = MyDataset(X_test)"
      ],
      "metadata": {
        "id": "2UtzMrdNRTN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GAT"
      ],
      "metadata": {
        "id": "YHpZUhvz-W--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#GAT\n",
        "\n",
        "from tensorflow.keras import constraints, initializers, regularizers\n",
        "from spektral.layers import ops\n",
        "from spektral.layers.convolutional.conv import Conv\n",
        "from spektral.layers.ops import modes\n",
        "\n",
        "\n",
        "class GAT(Conv):\n",
        "    def __init__(\n",
        "        self,\n",
        "        channels,\n",
        "        attn_heads=1,\n",
        "        concat_heads=True,\n",
        "        dropout_rate=0.5,\n",
        "        return_attn_coef=True,\n",
        "        add_self_loops=True,\n",
        "        activation=None,\n",
        "        use_bias=True,\n",
        "        kernel_initializer=\"glorot_uniform\",\n",
        "        bias_initializer=\"zeros\",\n",
        "        attn_kernel_initializer=\"glorot_uniform\",\n",
        "        kernel_regularizer=None,\n",
        "        bias_regularizer=None,\n",
        "        attn_kernel_regularizer=None,\n",
        "        activity_regularizer=None,\n",
        "        kernel_constraint=None,\n",
        "        bias_constraint=None,\n",
        "        attn_kernel_constraint=None,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(\n",
        "            activation=activation,\n",
        "            use_bias=use_bias,\n",
        "            kernel_initializer=kernel_initializer,\n",
        "            bias_initializer=bias_initializer,\n",
        "            kernel_regularizer=kernel_regularizer,\n",
        "            bias_regularizer=bias_regularizer,\n",
        "            activity_regularizer=activity_regularizer,\n",
        "            kernel_constraint=kernel_constraint,\n",
        "            bias_constraint=bias_constraint,\n",
        "            **kwargs\n",
        "        )\n",
        "        self.channels = channels\n",
        "        self.attn_heads = attn_heads\n",
        "        self.concat_heads = concat_heads\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.return_attn_coef = return_attn_coef\n",
        "        self.add_self_loops = add_self_loops\n",
        "        self.attn_kernel_initializer = initializers.get(attn_kernel_initializer)\n",
        "        self.attn_kernel_regularizer = regularizers.get(attn_kernel_regularizer)\n",
        "        self.attn_kernel_constraint = constraints.get(attn_kernel_constraint)\n",
        "\n",
        "        if concat_heads:\n",
        "            self.output_dim = self.channels * self.attn_heads\n",
        "        else:\n",
        "            self.output_dim = self.channels\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        input_dim = input_shape[0][-1]\n",
        "       \n",
        "        self.kernel = self.add_weight(\n",
        "            name=\"kernel\",\n",
        "            shape=[input_dim, self.attn_heads, self.channels],\n",
        "            initializer=self.kernel_initializer,\n",
        "            regularizer=self.kernel_regularizer,\n",
        "            constraint=self.kernel_constraint,\n",
        "        )\n",
        "        self.attn_kernel_self = self.add_weight(\n",
        "            name=\"attn_kernel_self\",\n",
        "            shape=[self.channels, self.attn_heads, 1],\n",
        "            initializer=self.attn_kernel_initializer,\n",
        "            regularizer=self.attn_kernel_regularizer,\n",
        "            constraint=self.attn_kernel_constraint,\n",
        "        )\n",
        "        self.attn_kernel_neighs = self.add_weight(\n",
        "            name=\"attn_kernel_neigh\",\n",
        "            shape=[self.channels, self.attn_heads, 1],\n",
        "            initializer=self.attn_kernel_initializer,\n",
        "            regularizer=self.attn_kernel_regularizer,\n",
        "            constraint=self.attn_kernel_constraint,\n",
        "        )\n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(\n",
        "                shape=[self.output_dim],\n",
        "                initializer=self.bias_initializer,\n",
        "                regularizer=self.bias_regularizer,\n",
        "                constraint=self.bias_constraint,\n",
        "                name=\"bias\",\n",
        "            )\n",
        "\n",
        "        self.dropout = Dropout(self.dropout_rate, dtype=self.dtype)\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        x, a = inputs\n",
        "\n",
        "        mode = ops.autodetect_mode(x, a)\n",
        "        if mode == modes.SINGLE and K.is_sparse(a):\n",
        "            output, attn_coef = self._call_single(x, a)\n",
        "        else:\n",
        "            if K.is_sparse(a):\n",
        "                a = tf.sparse.to_dense(a)\n",
        "            output, attn_coef = self._call_dense(x, a)\n",
        "\n",
        "        if self.concat_heads:\n",
        "            shape = tf.concat(\n",
        "                (tf.shape(output)[:-2], [self.attn_heads * self.channels]), axis=0\n",
        "            )\n",
        "            output = tf.reshape(output, shape)\n",
        "        else:\n",
        "            output = tf.reduce_mean(output, axis=-2)\n",
        "\n",
        "        if self.use_bias:\n",
        "            output += self.bias\n",
        "        if mask is not None:\n",
        "            output *= mask[0]\n",
        "        output = self.activation(output)\n",
        "\n",
        "        if self.return_attn_coef:\n",
        "            return output, attn_coef\n",
        "        else:\n",
        "            return output\n",
        "\n",
        "    def _call_single(self, x, a):\n",
        "        # Reshape kernels for efficient message-passing\n",
        "        kernel = tf.reshape(self.kernel, (-1, self.attn_heads * self.channels))\n",
        "        attn_kernel_self = ops.transpose(self.attn_kernel_self, (2, 1, 0))\n",
        "        attn_kernel_neighs = ops.transpose(self.attn_kernel_neighs, (2, 1, 0))\n",
        "\n",
        "        # Prepare message-passing\n",
        "        \n",
        "        indices = a.indices\n",
        "\n",
        "        N = tf.shape(x, out_type=indices.dtype)[-2]\n",
        "        if self.add_self_loops:\n",
        "            indices = ops.add_self_loops_indices(indices, N)\n",
        "       \n",
        "        targets, sources = indices[:, 1], indices[:, 0]\n",
        "        # # Update node features\n",
        "        x = K.dot(x, kernel)\n",
        "        x = tf.reshape(x, (-1, self.attn_heads, self.channels))\n",
        "\n",
        "        # Compute attention\n",
        "        attn_for_self = tf.reduce_sum(x * attn_kernel_self, -1) #sums up \"deep\" hidden representation after attention kernel operation.\n",
        "        attn_for_self = tf.gather(attn_for_self, targets) #targets recieve attention hence attention for self. e(h_i,h_j) -> edge j to i so source=j and target=i\n",
        "        attn_for_neighs = tf.reduce_sum(x * attn_kernel_neighs, -1)\n",
        "        attn_for_neighs = tf.gather(attn_for_neighs, sources) #sources give attention.\n",
        "        attn_coef = attn_for_self + attn_for_neighs\n",
        "        attn_coef = tf.nn.leaky_relu(attn_coef, alpha=0.2)\n",
        "        attn_coef = ops.unsorted_segment_softmax(attn_coef, targets, N)\n",
        "\n",
        "        attn_coef = self.dropout(attn_coef)\n",
        "        attn_coef = attn_coef[..., None]\n",
        "        # Update representation\n",
        "        output = attn_coef * tf.gather(x, sources)\n",
        "        output = tf.math.unsorted_segment_sum(output, targets, N)\n",
        "        \n",
        "        return output, attn_coef\n",
        "\n",
        "    def _call_dense(self, x, a):\n",
        "        shape = tf.shape(a)[:-1]\n",
        "        if self.add_self_loops:\n",
        "            a = tf.linalg.set_diag(a, tf.ones(shape, a.dtype))\n",
        "        x = tf.einsum(\"...NI , IHO -> ...NHO\", x, self.kernel)\n",
        "\n",
        "        attn_for_self = tf.einsum(\"...NHI , IHO -> ...NHO\", x, self.attn_kernel_self)\n",
        "\n",
        "        attn_for_neighs = tf.einsum(\n",
        "            \"...NHI , IHO -> ...NHO\", x, self.attn_kernel_neighs\n",
        "        )\n",
        "        attn_for_neighs = tf.einsum(\"...ABC -> ...CBA\", attn_for_neighs)\n",
        "\n",
        "        attn_coef = attn_for_self + attn_for_neighs\n",
        "        attn_coef = tf.nn.leaky_relu(attn_coef, alpha=0.2)\n",
        "\n",
        "        mask = tf.where(a == 0.0, -10e9, 0.0)\n",
        "        mask = tf.cast(mask, dtype=attn_coef.dtype)\n",
        "        attn_coef += mask[..., None, :]\n",
        "        attn_coef = tf.nn.softmax(attn_coef, axis=-1)\n",
        "        attn_coef_drop = self.dropout(attn_coef)\n",
        "\n",
        "        output = tf.einsum(\"...NHM , ...MHI -> ...NHI\", attn_coef_drop, x)\n",
        "        return output, attn_coef\n",
        "\n",
        "    @property\n",
        "    def config(self):\n",
        "        return {\n",
        "            \"channels\": self.channels,\n",
        "            \"attn_heads\": self.attn_heads,\n",
        "            \"concat_heads\": self.concat_heads,\n",
        "            \"dropout_rate\": self.dropout_rate,\n",
        "            \"return_attn_coef\": self.return_attn_coef,\n",
        "            \"attn_kernel_initializer\": initializers.serialize(\n",
        "                self.attn_kernel_initializer\n",
        "            ),\n",
        "            \"attn_kernel_regularizer\": regularizers.serialize(\n",
        "                self.attn_kernel_regularizer\n",
        "            ),\n",
        "            \"attn_kernel_constraint\": constraints.serialize(\n",
        "                self.attn_kernel_constraint\n",
        "            ),\n",
        "        }"
      ],
      "metadata": {
        "id": "9tdQ1Z1O9H3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GATV2"
      ],
      "metadata": {
        "id": "izCYhX71xmZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Gatv2-self-att\n",
        "from tensorflow.keras import constraints, initializers, regularizers\n",
        "\n",
        "from spektral.layers import ops\n",
        "from spektral.layers.convolutional.conv import Conv\n",
        "from spektral.layers.ops import modes\n",
        "\n",
        "\n",
        "class GATConv2(Conv):\n",
        "    def __init__(\n",
        "        self,\n",
        "        channels,\n",
        "        attn_heads=1,\n",
        "        concat_heads=True,#True for 8 heads\n",
        "        dropout_rate=0.5,\n",
        "        return_attn_coef=True,\n",
        "        add_self_loops=True,\n",
        "        activation=None,\n",
        "        use_bias=True,\n",
        "        kernel_initializer=\"glorot_uniform\",\n",
        "        bias_initializer=\"zeros\",\n",
        "        attn_kernel_initializer=\"glorot_uniform\",\n",
        "        kernel_regularizer=None,\n",
        "        bias_regularizer=None,\n",
        "        attn_kernel_regularizer=None,\n",
        "        activity_regularizer=None,\n",
        "        kernel_constraint=None,\n",
        "        bias_constraint=None,\n",
        "        attn_kernel_constraint=None,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(\n",
        "            activation=activation,\n",
        "            use_bias=use_bias,\n",
        "            kernel_initializer=kernel_initializer,\n",
        "            bias_initializer=bias_initializer,\n",
        "            kernel_regularizer=kernel_regularizer,\n",
        "            bias_regularizer=bias_regularizer,\n",
        "            activity_regularizer=activity_regularizer,\n",
        "            kernel_constraint=kernel_constraint,\n",
        "            bias_constraint=bias_constraint,\n",
        "            **kwargs\n",
        "        )\n",
        "        self.channels = channels\n",
        "        self.attn_heads = attn_heads\n",
        "        self.concat_heads = concat_heads\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.return_attn_coef = return_attn_coef\n",
        "        self.add_self_loops = add_self_loops\n",
        "        self.attn_kernel_initializer = initializers.get(attn_kernel_initializer)\n",
        "        self.attn_kernel_regularizer = regularizers.get(attn_kernel_regularizer)\n",
        "        self.attn_kernel_constraint = constraints.get(attn_kernel_constraint)\n",
        "\n",
        "        if concat_heads:\n",
        "            self.output_dim = self.channels * self.attn_heads\n",
        "        else:\n",
        "            self.output_dim = self.channels\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        input_dim = input_shape[0][-1]\n",
        "       \n",
        "        self.kernel = self.add_weight(\n",
        "            name=\"kernel\",\n",
        "            shape=[input_dim, self.attn_heads, self.channels],\n",
        "            initializer=self.kernel_initializer,\n",
        "            regularizer=self.kernel_regularizer,\n",
        "            constraint=self.kernel_constraint,\n",
        "        )\n",
        "        self.attn_kernel_self = self.add_weight(\n",
        "            name=\"attn_kernel_self\",\n",
        "            shape=[self.channels, self.attn_heads, 1],\n",
        "            initializer=self.attn_kernel_initializer,\n",
        "            regularizer=self.attn_kernel_regularizer,\n",
        "            constraint=self.attn_kernel_constraint,\n",
        "        )\n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(\n",
        "                shape=[self.output_dim],\n",
        "                initializer=self.bias_initializer,\n",
        "                regularizer=self.bias_regularizer,\n",
        "                constraint=self.bias_constraint,\n",
        "                name=\"bias\",\n",
        "            )\n",
        "\n",
        "        self.dropout = Dropout(self.dropout_rate, dtype=self.dtype)\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        x, a = inputs\n",
        "\n",
        "        mode = ops.autodetect_mode(x, a)\n",
        "        if mode == modes.SINGLE and K.is_sparse(a):\n",
        "            output, attn_coef = self._call_single(x, a)\n",
        "        else:\n",
        "            if K.is_sparse(a):\n",
        "                a = tf.sparse.to_dense(a)\n",
        "            output, attn_coef = self._call_dense(x, a)\n",
        "\n",
        "        if self.concat_heads:\n",
        "            shape = tf.concat(\n",
        "                (tf.shape(output)[:-2], [self.attn_heads * self.channels]), axis=0\n",
        "            )\n",
        "            output = tf.reshape(output, shape)\n",
        "        else:\n",
        "            output = tf.reduce_mean(output, axis=-2)\n",
        "\n",
        "        if self.use_bias:\n",
        "            output += self.bias\n",
        "        if mask is not None:\n",
        "            output *= mask[0]\n",
        "        output = self.activation(output)\n",
        "\n",
        "        if self.return_attn_coef:\n",
        "            return output, attn_coef\n",
        "        else:\n",
        "            return output\n",
        "\n",
        "    def _call_single(self, x, a):\n",
        "        # Reshape kernels for efficient message-passing\n",
        "        kernel = tf.reshape(self.kernel, (-1, self.attn_heads * self.channels))\n",
        "        attn_kernel_self = ops.transpose(self.attn_kernel_self, (2, 1, 0))\n",
        "   \n",
        "\n",
        "        # Prepare message-passing\n",
        "        \n",
        "        indices = a.indices\n",
        "\n",
        "        N = tf.shape(x, out_type=indices.dtype)[-2]\n",
        "        #print(N)\n",
        "        if self.add_self_loops:\n",
        "            indices = ops.add_self_loops_indices(indices, N)\n",
        "       \n",
        "        targets, sources = indices[:, 1], indices[:, 0]\n",
        "        # # Update node features\n",
        "\n",
        "        x = K.dot(x, kernel)\n",
        "        x = tf.reshape(x, (-1, self.attn_heads, self.channels))\n",
        "        xr = tf.nn.leaky_relu(x, alpha=0.2)\n",
        "        attn_for_self = tf.reduce_sum(xr * attn_kernel_self, -1)\n",
        "        attn_for_self = tf.gather(attn_for_self, targets)\n",
        "\n",
        "\n",
        "        # Compute attention\n",
        "        \n",
        "        attn_coef = ops.unsorted_segment_softmax(attn_for_self, targets, N)\n",
        "\n",
        "        attn_coef = self.dropout(attn_coef)\n",
        "        attn_coef = attn_coef[..., None]\n",
        "        output = attn_coef * tf.gather(x, sources)\n",
        "        output = tf.math.unsorted_segment_sum(output, targets, N)\n",
        "        \n",
        "        return output, attn_coef\n",
        "\n",
        "\n",
        "    @property\n",
        "    def config(self):\n",
        "        return {\n",
        "            \"channels\": self.channels,\n",
        "            \"attn_heads\": self.attn_heads,\n",
        "            \"concat_heads\": self.concat_heads,\n",
        "            \"dropout_rate\": self.dropout_rate,\n",
        "            \"return_attn_coef\": self.return_attn_coef,\n",
        "            \"attn_kernel_initializer\": initializers.serialize(\n",
        "                self.attn_kernel_initializer\n",
        "            ),\n",
        "            \"attn_kernel_regularizer\": regularizers.serialize(\n",
        "                self.attn_kernel_regularizer\n",
        "            ),\n",
        "            \"attn_kernel_constraint\": constraints.serialize(\n",
        "                self.attn_kernel_constraint\n",
        "            ),\n",
        "        }"
      ],
      "metadata": {
        "id": "JwRMae5JxkcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = nodes_num*2  # Number of nodes in the graph\n",
        "F = 2  # Original size of node features\n",
        "n_out = nodes_num  # Number of classes\n"
      ],
      "metadata": {
        "id": "jNKkduhAgBKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "channels = 128  # Number of channels in each head of the first GAT layer\n",
        "n_attn_heads = 1  # Number of attention heads in first GAT layer\n",
        "dropout = 0.0  # Dropout rate for the features and adjacency matrix\n",
        "l2_reg = 2.5e-4  # L2 regularization rate\n",
        "learning_rate = 0.001#5e-3  # Learning rate\n",
        "epochs = 20000  # Number of training epochs\n",
        "patience = 100  # Patience for early stopping\n",
        "\n",
        "# Model definition\n",
        "x_in = Input(shape=(F))\n",
        "a_in = Input((N), sparse=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "hZKu_6XG9o1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keys = tf.keras.layers.Embedding(nodes_num+1, 128)(x_in[:,0])\n",
        "values = tf.keras.layers.Embedding(nodes_num+1, 128)(x_in[:,1])\n",
        "attr = keys + values\n",
        "layer = tf.keras.layers.ReLU()\n",
        "attr = layer(attr)"
      ],
      "metadata": {
        "id": "SE-K7iEA9WRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GATConv2 for gat2\n",
        "gc_1 = GAT(\n",
        "    channels,\n",
        "    attn_heads=n_attn_heads,\n",
        "    concat_heads=False, #True When >=2heads else False\n",
        "    dropout_rate=dropout,\n",
        "    activation=\"relu\",\n",
        ")([attr, a_in])"
      ],
      "metadata": {
        "id": "sXmVzQniBHGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GATConv2 for gat2\n",
        "gc_2 = GAT(\n",
        "    n_out,\n",
        "    attn_heads=1,\n",
        "    concat_heads=False, #always False\n",
        "    dropout_rate=dropout,\n",
        "    activation=\"softmax\",\n",
        ")([gc_1[0], a_in])"
      ],
      "metadata": {
        "id": "maXNEyPBBKsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[x_in, a_in], outputs=gc_2)\n",
        "optimizer = Adam(learning_rate=learning_rate)"
      ],
      "metadata": {
        "id": "-6kWgP3nkON6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "hkKoD_ygBtSt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "647308bf-083f-40a8-b7a6-80bb7ca2cda5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_19 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_16 (S  (None,)             0           ['input_19[0][0]']               \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_17 (S  (None,)             0           ['input_19[0][0]']               \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " embedding_16 (Embedding)       (None, 128)          768         ['tf.__operators__.getitem_16[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " embedding_17 (Embedding)       (None, 128)          768         ['tf.__operators__.getitem_17[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.add_8 (TFOpLa  (None, 128)         0           ['embedding_16[0][0]',           \n",
            " mbda)                                                            'embedding_17[0][0]']           \n",
            "                                                                                                  \n",
            " re_lu_8 (ReLU)                 (None, 128)          0           ['tf.__operators__.add_8[0][0]'] \n",
            "                                                                                                  \n",
            " input_20 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " gat_1 (GAT)                    ((None, 128),        16768       ['re_lu_8[0][0]',                \n",
            "                                 (None, 1, 1))                    'input_20[0][0]']               \n",
            "                                                                                                  \n",
            " gat_2 (GAT)                    ((None, 5),          655         ['gat_1[0][0]',                  \n",
            "                                 (None, 1, 1))                    'input_20[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 18,959\n",
            "Trainable params: 18,959\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l=[]\n",
        "for step, g in enumerate(md1):\n",
        "  loader_tr  = SingleLoader(MyDataset([g]))\n",
        "  l.append(loader_tr.__next__())"
      ],
      "metadata": {
        "id": "M8aBHRdAyz9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "# Instantiate an optimizer.\n",
        "\n",
        "# Instantiate a loss function.\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n"
      ],
      "metadata": {
        "id": "nM_RYIXYCtrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "oUNrzmsd_rPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 4000\n",
        "acc=0\n",
        "running_loss = 0\n",
        "for epoch in range(epochs):\n",
        "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "\n",
        "    # Iterate over the batches of the dataset.\n",
        "    for step, g in enumerate(md1):\n",
        "        inputs, target = l[step]\n",
        "        # Open a GradientTape to record the operations run\n",
        "        # during the forward pass, which enables auto-differentiation.\n",
        "        with tf.GradientTape() as tape:\n",
        "\n",
        "            # Run the forward pass of the layer.\n",
        "            # The operations that the layer applies\n",
        "            # to its inputs are going to be recorded\n",
        "            # on the GradientTape.\n",
        "\n",
        "            logits, att = model(inputs, training=True)  # Logits for this minibatch\n",
        "            logits = logits[0:n_out]\n",
        "            # Compute the loss value for this minibatch.\n",
        "            loss_value = loss_fn(target, logits)\n",
        "            running_loss+=loss_value\n",
        "            acc += (tf.argmax(logits,1)==tf.reshape(target,-1)).numpy().sum()==len(tf.reshape(target,-1))\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "        # Use the gradient tape to automatically retrieve\n",
        "        # the gradients of the trainable variables with respect to the loss.\n",
        "        \n",
        "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "        if step%update==0:\n",
        "          old = [0]*len(grads)\n",
        "          for i,j in enumerate(grads):\n",
        "            if i >1:\n",
        "              old[i] = j + old[i]\n",
        "            else:\n",
        "              old[i] = tf.IndexedSlices(j.values + old[i] , j.indices,  j.dense_shape) \n",
        "      \n",
        "        else:\n",
        "          for i,j in enumerate(grads):\n",
        "            if i >1:\n",
        "              old[i] = j + old[i] \n",
        "            else:\n",
        "              old[i] = tf.IndexedSlices(j.values + old[i].values , j.indices,  j.dense_shape) \n",
        "        \n",
        "        # Run one step of gradient descent by updating\n",
        "        # the value of the variables to minimize the loss.\n",
        "        if step % update == update-1:\n",
        "    \n",
        "          for i,j in enumerate(old):\n",
        "            if i >1:\n",
        "              old[i] = j/update \n",
        "            else:\n",
        "              old[i] = tf.IndexedSlices(j.values/update , j.indices,  j.dense_shape) \n",
        "            \n",
        "          optimizer.apply_gradients(zip(old, model.trainable_weights))\n",
        "          old = [0]*len(grads)\n",
        "        # Log every 200 batches.\n",
        "        if step == 0 and epoch!=0:\n",
        "            print(\n",
        "                \"Training loss (for one batch) at step %d: %.4f\"\n",
        "                % (step, float(running_loss/mean_divisor))\n",
        "            )\n",
        "            \n",
        "            print(\n",
        "                \"Accuracy (for one batch) at step %d: %.4f\"\n",
        "                % (step, float(acc/mean_divisor))\n",
        "            )\n",
        "            acc=0\n",
        "            running_loss=0\n",
        "            print(\"Seen so far: %s samples\" % ((step + 1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCUo5-sLSpVx",
        "outputId": "6d6c43d6-42f1-4145-815e-1b609f9d58a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\n",
            "Start of epoch 2564\n",
            "Training loss (for one batch) at step 0: 0.7936\n",
            "Accuracy (for one batch) at step 0: 0.0111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2565\n",
            "Training loss (for one batch) at step 0: 0.7858\n",
            "Accuracy (for one batch) at step 0: 0.0111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2566\n",
            "Training loss (for one batch) at step 0: 0.7770\n",
            "Accuracy (for one batch) at step 0: 0.0222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2567\n",
            "Training loss (for one batch) at step 0: 0.7704\n",
            "Accuracy (for one batch) at step 0: 0.0222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2568\n",
            "Training loss (for one batch) at step 0: 0.7615\n",
            "Accuracy (for one batch) at step 0: 0.0111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2569\n",
            "Training loss (for one batch) at step 0: 0.7564\n",
            "Accuracy (for one batch) at step 0: 0.0222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2570\n",
            "Training loss (for one batch) at step 0: 0.7543\n",
            "Accuracy (for one batch) at step 0: 0.0333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2571\n",
            "Training loss (for one batch) at step 0: 0.7505\n",
            "Accuracy (for one batch) at step 0: 0.0333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2572\n",
            "Training loss (for one batch) at step 0: 0.7451\n",
            "Accuracy (for one batch) at step 0: 0.0333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2573\n",
            "Training loss (for one batch) at step 0: 0.7418\n",
            "Accuracy (for one batch) at step 0: 0.0222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2574\n",
            "Training loss (for one batch) at step 0: 0.7391\n",
            "Accuracy (for one batch) at step 0: 0.0333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2575\n",
            "Training loss (for one batch) at step 0: 0.7361\n",
            "Accuracy (for one batch) at step 0: 0.0333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2576\n",
            "Training loss (for one batch) at step 0: 0.7343\n",
            "Accuracy (for one batch) at step 0: 0.0222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2577\n",
            "Training loss (for one batch) at step 0: 0.7328\n",
            "Accuracy (for one batch) at step 0: 0.0333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2578\n",
            "Training loss (for one batch) at step 0: 0.7310\n",
            "Accuracy (for one batch) at step 0: 0.0222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2579\n",
            "Training loss (for one batch) at step 0: 0.7288\n",
            "Accuracy (for one batch) at step 0: 0.0222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2580\n",
            "Training loss (for one batch) at step 0: 0.7268\n",
            "Accuracy (for one batch) at step 0: 0.0222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2581\n",
            "Training loss (for one batch) at step 0: 0.7247\n",
            "Accuracy (for one batch) at step 0: 0.0222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2582\n",
            "Training loss (for one batch) at step 0: 0.7228\n",
            "Accuracy (for one batch) at step 0: 0.0222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2583\n",
            "Training loss (for one batch) at step 0: 0.7211\n",
            "Accuracy (for one batch) at step 0: 0.0222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2584\n",
            "Training loss (for one batch) at step 0: 0.7194\n",
            "Accuracy (for one batch) at step 0: 0.0222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2585\n",
            "Training loss (for one batch) at step 0: 0.7179\n",
            "Accuracy (for one batch) at step 0: 0.0111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2586\n",
            "Training loss (for one batch) at step 0: 0.7164\n",
            "Accuracy (for one batch) at step 0: 0.0222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2587\n",
            "Training loss (for one batch) at step 0: 0.7152\n",
            "Accuracy (for one batch) at step 0: 0.0222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2588\n",
            "Training loss (for one batch) at step 0: 0.7138\n",
            "Accuracy (for one batch) at step 0: 0.0222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2589\n",
            "Training loss (for one batch) at step 0: 0.7125\n",
            "Accuracy (for one batch) at step 0: 0.0222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2590\n",
            "Training loss (for one batch) at step 0: 0.7115\n",
            "Accuracy (for one batch) at step 0: 0.0222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2591\n",
            "Training loss (for one batch) at step 0: 0.7103\n",
            "Accuracy (for one batch) at step 0: 0.0222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2592\n",
            "Training loss (for one batch) at step 0: 0.7085\n",
            "Accuracy (for one batch) at step 0: 0.0111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2593\n",
            "Training loss (for one batch) at step 0: 0.7061\n",
            "Accuracy (for one batch) at step 0: 0.0111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2594\n",
            "Training loss (for one batch) at step 0: 0.7040\n",
            "Accuracy (for one batch) at step 0: 0.0333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2595\n",
            "Training loss (for one batch) at step 0: 0.7024\n",
            "Accuracy (for one batch) at step 0: 0.0222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2596\n",
            "Training loss (for one batch) at step 0: 0.7009\n",
            "Accuracy (for one batch) at step 0: 0.0222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2597\n",
            "Training loss (for one batch) at step 0: 0.6995\n",
            "Accuracy (for one batch) at step 0: 0.0333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2598\n",
            "Training loss (for one batch) at step 0: 0.6980\n",
            "Accuracy (for one batch) at step 0: 0.0333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2599\n",
            "Training loss (for one batch) at step 0: 0.6967\n",
            "Accuracy (for one batch) at step 0: 0.0222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2600\n",
            "Training loss (for one batch) at step 0: 0.6955\n",
            "Accuracy (for one batch) at step 0: 0.0333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2601\n",
            "Training loss (for one batch) at step 0: 0.6944\n",
            "Accuracy (for one batch) at step 0: 0.0333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2602\n",
            "Training loss (for one batch) at step 0: 0.6932\n",
            "Accuracy (for one batch) at step 0: 0.0444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2603\n",
            "Training loss (for one batch) at step 0: 0.6918\n",
            "Accuracy (for one batch) at step 0: 0.0333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2604\n",
            "Training loss (for one batch) at step 0: 0.6912\n",
            "Accuracy (for one batch) at step 0: 0.0333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2605\n",
            "Training loss (for one batch) at step 0: 0.6899\n",
            "Accuracy (for one batch) at step 0: 0.0444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2606\n",
            "Training loss (for one batch) at step 0: 0.6888\n",
            "Accuracy (for one batch) at step 0: 0.0333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2607\n",
            "Training loss (for one batch) at step 0: 0.6883\n",
            "Accuracy (for one batch) at step 0: 0.0444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2608\n",
            "Training loss (for one batch) at step 0: 0.6870\n",
            "Accuracy (for one batch) at step 0: 0.0444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2609\n",
            "Training loss (for one batch) at step 0: 0.6858\n",
            "Accuracy (for one batch) at step 0: 0.0333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2610\n",
            "Training loss (for one batch) at step 0: 0.6849\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2611\n",
            "Training loss (for one batch) at step 0: 0.6839\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2612\n",
            "Training loss (for one batch) at step 0: 0.6831\n",
            "Accuracy (for one batch) at step 0: 0.0444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2613\n",
            "Training loss (for one batch) at step 0: 0.6825\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2614\n",
            "Training loss (for one batch) at step 0: 0.6819\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2615\n",
            "Training loss (for one batch) at step 0: 0.6817\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2616\n",
            "Training loss (for one batch) at step 0: 0.6808\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2617\n",
            "Training loss (for one batch) at step 0: 0.6797\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2618\n",
            "Training loss (for one batch) at step 0: 0.6788\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2619\n",
            "Training loss (for one batch) at step 0: 0.6790\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2620\n",
            "Training loss (for one batch) at step 0: 0.6778\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2621\n",
            "Training loss (for one batch) at step 0: 0.6769\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2622\n",
            "Training loss (for one batch) at step 0: 0.6773\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2623\n",
            "Training loss (for one batch) at step 0: 0.6758\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2624\n",
            "Training loss (for one batch) at step 0: 0.6756\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2625\n",
            "Training loss (for one batch) at step 0: 0.6748\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2626\n",
            "Training loss (for one batch) at step 0: 0.6740\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2627\n",
            "Training loss (for one batch) at step 0: 0.6730\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2628\n",
            "Training loss (for one batch) at step 0: 0.6726\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2629\n",
            "Training loss (for one batch) at step 0: 0.6718\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2630\n",
            "Training loss (for one batch) at step 0: 0.6711\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2631\n",
            "Training loss (for one batch) at step 0: 0.6706\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2632\n",
            "Training loss (for one batch) at step 0: 0.6704\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2633\n",
            "Training loss (for one batch) at step 0: 0.6697\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2634\n",
            "Training loss (for one batch) at step 0: 0.6697\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2635\n",
            "Training loss (for one batch) at step 0: 0.6690\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2636\n",
            "Training loss (for one batch) at step 0: 0.6683\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2637\n",
            "Training loss (for one batch) at step 0: 0.6682\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2638\n",
            "Training loss (for one batch) at step 0: 0.6670\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2639\n",
            "Training loss (for one batch) at step 0: 0.6671\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2640\n",
            "Training loss (for one batch) at step 0: 0.6676\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2641\n",
            "Training loss (for one batch) at step 0: 0.6667\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2642\n",
            "Training loss (for one batch) at step 0: 0.6655\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2643\n",
            "Training loss (for one batch) at step 0: 0.6657\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2644\n",
            "Training loss (for one batch) at step 0: 0.6645\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2645\n",
            "Training loss (for one batch) at step 0: 0.6640\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2646\n",
            "Training loss (for one batch) at step 0: 0.6630\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2647\n",
            "Training loss (for one batch) at step 0: 0.6625\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2648\n",
            "Training loss (for one batch) at step 0: 0.6635\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2649\n",
            "Training loss (for one batch) at step 0: 0.6619\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2650\n",
            "Training loss (for one batch) at step 0: 0.6614\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2651\n",
            "Training loss (for one batch) at step 0: 0.6611\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2652\n",
            "Training loss (for one batch) at step 0: 0.6601\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2653\n",
            "Training loss (for one batch) at step 0: 0.6600\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2654\n",
            "Training loss (for one batch) at step 0: 0.6600\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2655\n",
            "Training loss (for one batch) at step 0: 0.6588\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2656\n",
            "Training loss (for one batch) at step 0: 0.6586\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2657\n",
            "Training loss (for one batch) at step 0: 0.6592\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2658\n",
            "Training loss (for one batch) at step 0: 0.6584\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2659\n",
            "Training loss (for one batch) at step 0: 0.6573\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2660\n",
            "Training loss (for one batch) at step 0: 0.6585\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2661\n",
            "Training loss (for one batch) at step 0: 0.6579\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2662\n",
            "Training loss (for one batch) at step 0: 0.6570\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2663\n",
            "Training loss (for one batch) at step 0: 0.6590\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2664\n",
            "Training loss (for one batch) at step 0: 0.6594\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2665\n",
            "Training loss (for one batch) at step 0: 0.6574\n",
            "Accuracy (for one batch) at step 0: 0.0444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2666\n",
            "Training loss (for one batch) at step 0: 0.6571\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2667\n",
            "Training loss (for one batch) at step 0: 0.6564\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2668\n",
            "Training loss (for one batch) at step 0: 0.6538\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2669\n",
            "Training loss (for one batch) at step 0: 0.6569\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2670\n",
            "Training loss (for one batch) at step 0: 0.6569\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2671\n",
            "Training loss (for one batch) at step 0: 0.6533\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2672\n",
            "Training loss (for one batch) at step 0: 0.6587\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2673\n",
            "Training loss (for one batch) at step 0: 0.6622\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2674\n",
            "Training loss (for one batch) at step 0: 0.6576\n",
            "Accuracy (for one batch) at step 0: 0.0444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2675\n",
            "Training loss (for one batch) at step 0: 0.6538\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2676\n",
            "Training loss (for one batch) at step 0: 0.6547\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2677\n",
            "Training loss (for one batch) at step 0: 0.6525\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2678\n",
            "Training loss (for one batch) at step 0: 0.6522\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2679\n",
            "Training loss (for one batch) at step 0: 0.6520\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2680\n",
            "Training loss (for one batch) at step 0: 0.6506\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2681\n",
            "Training loss (for one batch) at step 0: 0.6487\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2682\n",
            "Training loss (for one batch) at step 0: 0.6490\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2683\n",
            "Training loss (for one batch) at step 0: 0.6471\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2684\n",
            "Training loss (for one batch) at step 0: 0.6482\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2685\n",
            "Training loss (for one batch) at step 0: 0.6474\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2686\n",
            "Training loss (for one batch) at step 0: 0.6470\n",
            "Accuracy (for one batch) at step 0: 0.0444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2687\n",
            "Training loss (for one batch) at step 0: 0.6454\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2688\n",
            "Training loss (for one batch) at step 0: 0.6462\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2689\n",
            "Training loss (for one batch) at step 0: 0.6472\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2690\n",
            "Training loss (for one batch) at step 0: 0.6476\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2691\n",
            "Training loss (for one batch) at step 0: 0.6484\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2692\n",
            "Training loss (for one batch) at step 0: 0.6475\n",
            "Accuracy (for one batch) at step 0: 0.0444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2693\n",
            "Training loss (for one batch) at step 0: 0.6459\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2694\n",
            "Training loss (for one batch) at step 0: 0.6430\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2695\n",
            "Training loss (for one batch) at step 0: 0.6428\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2696\n",
            "Training loss (for one batch) at step 0: 0.6430\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2697\n",
            "Training loss (for one batch) at step 0: 0.6405\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2698\n",
            "Training loss (for one batch) at step 0: 0.6404\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2699\n",
            "Training loss (for one batch) at step 0: 0.6466\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2700\n",
            "Training loss (for one batch) at step 0: 0.6437\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2701\n",
            "Training loss (for one batch) at step 0: 0.6435\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2702\n",
            "Training loss (for one batch) at step 0: 0.6419\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2703\n",
            "Training loss (for one batch) at step 0: 0.6416\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2704\n",
            "Training loss (for one batch) at step 0: 0.6389\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2705\n",
            "Training loss (for one batch) at step 0: 0.6402\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2706\n",
            "Training loss (for one batch) at step 0: 0.6370\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2707\n",
            "Training loss (for one batch) at step 0: 0.6399\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2708\n",
            "Training loss (for one batch) at step 0: 0.6425\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2709\n",
            "Training loss (for one batch) at step 0: 0.6413\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2710\n",
            "Training loss (for one batch) at step 0: 0.6483\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2711\n",
            "Training loss (for one batch) at step 0: 0.6476\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2712\n",
            "Training loss (for one batch) at step 0: 0.6458\n",
            "Accuracy (for one batch) at step 0: 0.0444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2713\n",
            "Training loss (for one batch) at step 0: 0.6431\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2714\n",
            "Training loss (for one batch) at step 0: 0.6459\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2715\n",
            "Training loss (for one batch) at step 0: 0.6415\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2716\n",
            "Training loss (for one batch) at step 0: 0.6471\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2717\n",
            "Training loss (for one batch) at step 0: 0.6402\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2718\n",
            "Training loss (for one batch) at step 0: 0.6434\n",
            "Accuracy (for one batch) at step 0: 0.0444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2719\n",
            "Training loss (for one batch) at step 0: 0.6358\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2720\n",
            "Training loss (for one batch) at step 0: 0.6362\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2721\n",
            "Training loss (for one batch) at step 0: 0.6314\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2722\n",
            "Training loss (for one batch) at step 0: 0.6337\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2723\n",
            "Training loss (for one batch) at step 0: 0.6285\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2724\n",
            "Training loss (for one batch) at step 0: 0.6262\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2725\n",
            "Training loss (for one batch) at step 0: 0.6252\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2726\n",
            "Training loss (for one batch) at step 0: 0.6272\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2727\n",
            "Training loss (for one batch) at step 0: 0.6240\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2728\n",
            "Training loss (for one batch) at step 0: 0.6240\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2729\n",
            "Training loss (for one batch) at step 0: 0.6246\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2730\n",
            "Training loss (for one batch) at step 0: 0.6246\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2731\n",
            "Training loss (for one batch) at step 0: 0.6339\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2732\n",
            "Training loss (for one batch) at step 0: 0.6327\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2733\n",
            "Training loss (for one batch) at step 0: 0.6340\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2734\n",
            "Training loss (for one batch) at step 0: 0.6343\n",
            "Accuracy (for one batch) at step 0: 0.0444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2735\n",
            "Training loss (for one batch) at step 0: 0.6318\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2736\n",
            "Training loss (for one batch) at step 0: 0.6364\n",
            "Accuracy (for one batch) at step 0: 0.0444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2737\n",
            "Training loss (for one batch) at step 0: 0.6327\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2738\n",
            "Training loss (for one batch) at step 0: 0.6305\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2739\n",
            "Training loss (for one batch) at step 0: 0.6272\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2740\n",
            "Training loss (for one batch) at step 0: 0.6226\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2741\n",
            "Training loss (for one batch) at step 0: 0.6189\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2742\n",
            "Training loss (for one batch) at step 0: 0.6176\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2743\n",
            "Training loss (for one batch) at step 0: 0.6184\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2744\n",
            "Training loss (for one batch) at step 0: 0.6187\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2745\n",
            "Training loss (for one batch) at step 0: 0.6154\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2746\n",
            "Training loss (for one batch) at step 0: 0.6159\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2747\n",
            "Training loss (for one batch) at step 0: 0.6155\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2748\n",
            "Training loss (for one batch) at step 0: 0.6152\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2749\n",
            "Training loss (for one batch) at step 0: 0.6182\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2750\n",
            "Training loss (for one batch) at step 0: 0.6217\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2751\n",
            "Training loss (for one batch) at step 0: 0.6199\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2752\n",
            "Training loss (for one batch) at step 0: 0.6192\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2753\n",
            "Training loss (for one batch) at step 0: 0.6226\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2754\n",
            "Training loss (for one batch) at step 0: 0.6177\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2755\n",
            "Training loss (for one batch) at step 0: 0.6160\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2756\n",
            "Training loss (for one batch) at step 0: 0.6195\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2757\n",
            "Training loss (for one batch) at step 0: 0.6172\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2758\n",
            "Training loss (for one batch) at step 0: 0.6262\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2759\n",
            "Training loss (for one batch) at step 0: 0.6286\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2760\n",
            "Training loss (for one batch) at step 0: 0.6279\n",
            "Accuracy (for one batch) at step 0: 0.0444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2761\n",
            "Training loss (for one batch) at step 0: 0.6194\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2762\n",
            "Training loss (for one batch) at step 0: 0.6194\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2763\n",
            "Training loss (for one batch) at step 0: 0.6157\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2764\n",
            "Training loss (for one batch) at step 0: 0.6246\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2765\n",
            "Training loss (for one batch) at step 0: 0.6292\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2766\n",
            "Training loss (for one batch) at step 0: 0.6654\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2767\n",
            "Training loss (for one batch) at step 0: 0.6797\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2768\n",
            "Training loss (for one batch) at step 0: 0.6712\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2769\n",
            "Training loss (for one batch) at step 0: 0.6626\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2770\n",
            "Training loss (for one batch) at step 0: 0.6584\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2771\n",
            "Training loss (for one batch) at step 0: 0.6438\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2772\n",
            "Training loss (for one batch) at step 0: 0.6389\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2773\n",
            "Training loss (for one batch) at step 0: 0.6310\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2774\n",
            "Training loss (for one batch) at step 0: 0.6173\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2775\n",
            "Training loss (for one batch) at step 0: 0.6179\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2776\n",
            "Training loss (for one batch) at step 0: 0.6214\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2777\n",
            "Training loss (for one batch) at step 0: 0.6169\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2778\n",
            "Training loss (for one batch) at step 0: 0.6186\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2779\n",
            "Training loss (for one batch) at step 0: 0.6070\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2780\n",
            "Training loss (for one batch) at step 0: 0.6080\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2781\n",
            "Training loss (for one batch) at step 0: 0.6082\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2782\n",
            "Training loss (for one batch) at step 0: 0.6058\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2783\n",
            "Training loss (for one batch) at step 0: 0.6042\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2784\n",
            "Training loss (for one batch) at step 0: 0.6021\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2785\n",
            "Training loss (for one batch) at step 0: 0.6011\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2786\n",
            "Training loss (for one batch) at step 0: 0.5997\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2787\n",
            "Training loss (for one batch) at step 0: 0.5983\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2788\n",
            "Training loss (for one batch) at step 0: 0.5956\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2789\n",
            "Training loss (for one batch) at step 0: 0.5950\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2790\n",
            "Training loss (for one batch) at step 0: 0.5947\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2791\n",
            "Training loss (for one batch) at step 0: 0.5929\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2792\n",
            "Training loss (for one batch) at step 0: 0.5925\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2793\n",
            "Training loss (for one batch) at step 0: 0.5923\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2794\n",
            "Training loss (for one batch) at step 0: 0.5914\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2795\n",
            "Training loss (for one batch) at step 0: 0.5908\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2796\n",
            "Training loss (for one batch) at step 0: 0.5902\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2797\n",
            "Training loss (for one batch) at step 0: 0.5899\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2798\n",
            "Training loss (for one batch) at step 0: 0.5895\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2799\n",
            "Training loss (for one batch) at step 0: 0.5887\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2800\n",
            "Training loss (for one batch) at step 0: 0.5882\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2801\n",
            "Training loss (for one batch) at step 0: 0.5886\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2802\n",
            "Training loss (for one batch) at step 0: 0.5884\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2803\n",
            "Training loss (for one batch) at step 0: 0.5885\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2804\n",
            "Training loss (for one batch) at step 0: 0.5910\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2805\n",
            "Training loss (for one batch) at step 0: 0.5962\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2806\n",
            "Training loss (for one batch) at step 0: 0.6110\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2807\n",
            "Training loss (for one batch) at step 0: 0.6129\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2808\n",
            "Training loss (for one batch) at step 0: 0.6019\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2809\n",
            "Training loss (for one batch) at step 0: 0.6026\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2810\n",
            "Training loss (for one batch) at step 0: 0.6018\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2811\n",
            "Training loss (for one batch) at step 0: 0.6004\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2812\n",
            "Training loss (for one batch) at step 0: 0.6014\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2813\n",
            "Training loss (for one batch) at step 0: 0.5991\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2814\n",
            "Training loss (for one batch) at step 0: 0.5971\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2815\n",
            "Training loss (for one batch) at step 0: 0.5947\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2816\n",
            "Training loss (for one batch) at step 0: 0.6089\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2817\n",
            "Training loss (for one batch) at step 0: 0.6078\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2818\n",
            "Training loss (for one batch) at step 0: 0.6083\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2819\n",
            "Training loss (for one batch) at step 0: 0.6216\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2820\n",
            "Training loss (for one batch) at step 0: 0.6290\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2821\n",
            "Training loss (for one batch) at step 0: 0.6353\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2822\n",
            "Training loss (for one batch) at step 0: 0.6208\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2823\n",
            "Training loss (for one batch) at step 0: 0.6236\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2824\n",
            "Training loss (for one batch) at step 0: 0.6126\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2825\n",
            "Training loss (for one batch) at step 0: 0.6009\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2826\n",
            "Training loss (for one batch) at step 0: 0.6000\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2827\n",
            "Training loss (for one batch) at step 0: 0.5931\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2828\n",
            "Training loss (for one batch) at step 0: 0.5938\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2829\n",
            "Training loss (for one batch) at step 0: 0.5926\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2830\n",
            "Training loss (for one batch) at step 0: 0.5871\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2831\n",
            "Training loss (for one batch) at step 0: 0.5903\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2832\n",
            "Training loss (for one batch) at step 0: 0.5850\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2833\n",
            "Training loss (for one batch) at step 0: 0.5816\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2834\n",
            "Training loss (for one batch) at step 0: 0.5824\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2835\n",
            "Training loss (for one batch) at step 0: 0.5814\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2836\n",
            "Training loss (for one batch) at step 0: 0.5797\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2837\n",
            "Training loss (for one batch) at step 0: 0.5790\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2838\n",
            "Training loss (for one batch) at step 0: 0.5777\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2839\n",
            "Training loss (for one batch) at step 0: 0.5782\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2840\n",
            "Training loss (for one batch) at step 0: 0.5780\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2841\n",
            "Training loss (for one batch) at step 0: 0.5758\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2842\n",
            "Training loss (for one batch) at step 0: 0.5748\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2843\n",
            "Training loss (for one batch) at step 0: 0.5746\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2844\n",
            "Training loss (for one batch) at step 0: 0.5736\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2845\n",
            "Training loss (for one batch) at step 0: 0.5737\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2846\n",
            "Training loss (for one batch) at step 0: 0.5729\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2847\n",
            "Training loss (for one batch) at step 0: 0.5724\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2848\n",
            "Training loss (for one batch) at step 0: 0.5714\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2849\n",
            "Training loss (for one batch) at step 0: 0.5700\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2850\n",
            "Training loss (for one batch) at step 0: 0.5692\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2851\n",
            "Training loss (for one batch) at step 0: 0.5685\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2852\n",
            "Training loss (for one batch) at step 0: 0.5679\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2853\n",
            "Training loss (for one batch) at step 0: 0.5683\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2854\n",
            "Training loss (for one batch) at step 0: 0.5679\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2855\n",
            "Training loss (for one batch) at step 0: 0.5684\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2856\n",
            "Training loss (for one batch) at step 0: 0.5695\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2857\n",
            "Training loss (for one batch) at step 0: 0.5713\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2858\n",
            "Training loss (for one batch) at step 0: 0.5754\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2859\n",
            "Training loss (for one batch) at step 0: 0.5791\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2860\n",
            "Training loss (for one batch) at step 0: 0.5898\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2861\n",
            "Training loss (for one batch) at step 0: 0.5902\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2862\n",
            "Training loss (for one batch) at step 0: 0.6132\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2863\n",
            "Training loss (for one batch) at step 0: 1.6907\n",
            "Accuracy (for one batch) at step 0: 0.0222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2864\n",
            "Training loss (for one batch) at step 0: 1.3812\n",
            "Accuracy (for one batch) at step 0: 0.0111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2865\n",
            "Training loss (for one batch) at step 0: 1.0957\n",
            "Accuracy (for one batch) at step 0: 0.0111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2866\n",
            "Training loss (for one batch) at step 0: 1.1148\n",
            "Accuracy (for one batch) at step 0: 0.0222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2867\n",
            "Training loss (for one batch) at step 0: 1.0868\n",
            "Accuracy (for one batch) at step 0: 0.0222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2868\n",
            "Training loss (for one batch) at step 0: 1.1318\n",
            "Accuracy (for one batch) at step 0: 0.0111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2869\n",
            "Training loss (for one batch) at step 0: 0.9498\n",
            "Accuracy (for one batch) at step 0: 0.0111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2870\n",
            "Training loss (for one batch) at step 0: 0.7910\n",
            "Accuracy (for one batch) at step 0: 0.0444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2871\n",
            "Training loss (for one batch) at step 0: 0.8405\n",
            "Accuracy (for one batch) at step 0: 0.0444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2872\n",
            "Training loss (for one batch) at step 0: 0.7863\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2873\n",
            "Training loss (for one batch) at step 0: 0.7872\n",
            "Accuracy (for one batch) at step 0: 0.0111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2874\n",
            "Training loss (for one batch) at step 0: 0.7486\n",
            "Accuracy (for one batch) at step 0: 0.0222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2875\n",
            "Training loss (for one batch) at step 0: 0.7312\n",
            "Accuracy (for one batch) at step 0: 0.0222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2876\n",
            "Training loss (for one batch) at step 0: 0.7186\n",
            "Accuracy (for one batch) at step 0: 0.0222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2877\n",
            "Training loss (for one batch) at step 0: 0.6910\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2878\n",
            "Training loss (for one batch) at step 0: 0.6872\n",
            "Accuracy (for one batch) at step 0: 0.0444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2879\n",
            "Training loss (for one batch) at step 0: 0.6665\n",
            "Accuracy (for one batch) at step 0: 0.0444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2880\n",
            "Training loss (for one batch) at step 0: 0.6689\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2881\n",
            "Training loss (for one batch) at step 0: 0.6789\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2882\n",
            "Training loss (for one batch) at step 0: 0.6677\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2883\n",
            "Training loss (for one batch) at step 0: 0.6507\n",
            "Accuracy (for one batch) at step 0: 0.0444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2884\n",
            "Training loss (for one batch) at step 0: 0.6420\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2885\n",
            "Training loss (for one batch) at step 0: 0.6360\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2886\n",
            "Training loss (for one batch) at step 0: 0.6256\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2887\n",
            "Training loss (for one batch) at step 0: 0.6136\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2888\n",
            "Training loss (for one batch) at step 0: 0.6026\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2889\n",
            "Training loss (for one batch) at step 0: 0.5873\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2890\n",
            "Training loss (for one batch) at step 0: 0.5819\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2891\n",
            "Training loss (for one batch) at step 0: 0.5802\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2892\n",
            "Training loss (for one batch) at step 0: 0.5767\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2893\n",
            "Training loss (for one batch) at step 0: 0.5725\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2894\n",
            "Training loss (for one batch) at step 0: 0.5689\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2895\n",
            "Training loss (for one batch) at step 0: 0.5671\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2896\n",
            "Training loss (for one batch) at step 0: 0.5650\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2897\n",
            "Training loss (for one batch) at step 0: 0.5637\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2898\n",
            "Training loss (for one batch) at step 0: 0.5632\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2899\n",
            "Training loss (for one batch) at step 0: 0.5611\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2900\n",
            "Training loss (for one batch) at step 0: 0.5628\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2901\n",
            "Training loss (for one batch) at step 0: 0.5602\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2902\n",
            "Training loss (for one batch) at step 0: 0.5615\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2903\n",
            "Training loss (for one batch) at step 0: 0.5591\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2904\n",
            "Training loss (for one batch) at step 0: 0.5609\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2905\n",
            "Training loss (for one batch) at step 0: 0.5597\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2906\n",
            "Training loss (for one batch) at step 0: 0.5700\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2907\n",
            "Training loss (for one batch) at step 0: 0.5712\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2908\n",
            "Training loss (for one batch) at step 0: 0.5747\n",
            "Accuracy (for one batch) at step 0: 0.0444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2909\n",
            "Training loss (for one batch) at step 0: 0.5760\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2910\n",
            "Training loss (for one batch) at step 0: 0.5727\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2911\n",
            "Training loss (for one batch) at step 0: 0.5753\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2912\n",
            "Training loss (for one batch) at step 0: 0.5701\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2913\n",
            "Training loss (for one batch) at step 0: 0.5593\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2914\n",
            "Training loss (for one batch) at step 0: 0.5561\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2915\n",
            "Training loss (for one batch) at step 0: 0.5533\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2916\n",
            "Training loss (for one batch) at step 0: 0.5515\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2917\n",
            "Training loss (for one batch) at step 0: 0.5510\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2918\n",
            "Training loss (for one batch) at step 0: 0.5499\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2919\n",
            "Training loss (for one batch) at step 0: 0.5511\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2920\n",
            "Training loss (for one batch) at step 0: 0.5509\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2921\n",
            "Training loss (for one batch) at step 0: 0.5561\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2922\n",
            "Training loss (for one batch) at step 0: 0.5546\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2923\n",
            "Training loss (for one batch) at step 0: 0.5579\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2924\n",
            "Training loss (for one batch) at step 0: 0.5558\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2925\n",
            "Training loss (for one batch) at step 0: 0.5621\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2926\n",
            "Training loss (for one batch) at step 0: 0.5737\n",
            "Accuracy (for one batch) at step 0: 0.0444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2927\n",
            "Training loss (for one batch) at step 0: 0.5715\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2928\n",
            "Training loss (for one batch) at step 0: 0.5902\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2929\n",
            "Training loss (for one batch) at step 0: 0.5819\n",
            "Accuracy (for one batch) at step 0: 0.0444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2930\n",
            "Training loss (for one batch) at step 0: 0.5687\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2931\n",
            "Training loss (for one batch) at step 0: 0.5622\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2932\n",
            "Training loss (for one batch) at step 0: 0.5511\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2933\n",
            "Training loss (for one batch) at step 0: 0.5491\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2934\n",
            "Training loss (for one batch) at step 0: 0.5475\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2935\n",
            "Training loss (for one batch) at step 0: 0.5464\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2936\n",
            "Training loss (for one batch) at step 0: 0.5463\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2937\n",
            "Training loss (for one batch) at step 0: 0.5440\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2938\n",
            "Training loss (for one batch) at step 0: 0.5467\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2939\n",
            "Training loss (for one batch) at step 0: 0.5458\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2940\n",
            "Training loss (for one batch) at step 0: 0.5481\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2941\n",
            "Training loss (for one batch) at step 0: 0.5461\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2942\n",
            "Training loss (for one batch) at step 0: 0.5486\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2943\n",
            "Training loss (for one batch) at step 0: 0.5427\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2944\n",
            "Training loss (for one batch) at step 0: 0.5460\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2945\n",
            "Training loss (for one batch) at step 0: 0.5440\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2946\n",
            "Training loss (for one batch) at step 0: 0.5464\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2947\n",
            "Training loss (for one batch) at step 0: 0.5427\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2948\n",
            "Training loss (for one batch) at step 0: 0.5466\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2949\n",
            "Training loss (for one batch) at step 0: 0.5455\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2950\n",
            "Training loss (for one batch) at step 0: 0.5471\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2951\n",
            "Training loss (for one batch) at step 0: 0.5431\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2952\n",
            "Training loss (for one batch) at step 0: 0.5504\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2953\n",
            "Training loss (for one batch) at step 0: 0.5447\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2954\n",
            "Training loss (for one batch) at step 0: 0.5460\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2955\n",
            "Training loss (for one batch) at step 0: 0.5472\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2956\n",
            "Training loss (for one batch) at step 0: 0.5542\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2957\n",
            "Training loss (for one batch) at step 0: 0.5484\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2958\n",
            "Training loss (for one batch) at step 0: 0.5496\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2959\n",
            "Training loss (for one batch) at step 0: 0.5544\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2960\n",
            "Training loss (for one batch) at step 0: 0.5599\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2961\n",
            "Training loss (for one batch) at step 0: 0.5494\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2962\n",
            "Training loss (for one batch) at step 0: 0.5482\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2963\n",
            "Training loss (for one batch) at step 0: 0.5482\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2964\n",
            "Training loss (for one batch) at step 0: 0.5448\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2965\n",
            "Training loss (for one batch) at step 0: 0.5388\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2966\n",
            "Training loss (for one batch) at step 0: 0.5364\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2967\n",
            "Training loss (for one batch) at step 0: 0.5346\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2968\n",
            "Training loss (for one batch) at step 0: 0.5337\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2969\n",
            "Training loss (for one batch) at step 0: 0.5322\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2970\n",
            "Training loss (for one batch) at step 0: 0.5332\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2971\n",
            "Training loss (for one batch) at step 0: 0.5311\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2972\n",
            "Training loss (for one batch) at step 0: 0.5322\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2973\n",
            "Training loss (for one batch) at step 0: 0.5306\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2974\n",
            "Training loss (for one batch) at step 0: 0.5309\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2975\n",
            "Training loss (for one batch) at step 0: 0.5293\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2976\n",
            "Training loss (for one batch) at step 0: 0.5307\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2977\n",
            "Training loss (for one batch) at step 0: 0.5292\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2978\n",
            "Training loss (for one batch) at step 0: 0.5291\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2979\n",
            "Training loss (for one batch) at step 0: 0.5287\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2980\n",
            "Training loss (for one batch) at step 0: 0.5275\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2981\n",
            "Training loss (for one batch) at step 0: 0.5286\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2982\n",
            "Training loss (for one batch) at step 0: 0.5270\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2983\n",
            "Training loss (for one batch) at step 0: 0.5282\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2984\n",
            "Training loss (for one batch) at step 0: 0.5262\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2985\n",
            "Training loss (for one batch) at step 0: 0.5282\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2986\n",
            "Training loss (for one batch) at step 0: 0.5259\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2987\n",
            "Training loss (for one batch) at step 0: 0.5262\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2988\n",
            "Training loss (for one batch) at step 0: 0.5257\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2989\n",
            "Training loss (for one batch) at step 0: 0.5242\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2990\n",
            "Training loss (for one batch) at step 0: 0.5246\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2991\n",
            "Training loss (for one batch) at step 0: 0.5253\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2992\n",
            "Training loss (for one batch) at step 0: 0.5264\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2993\n",
            "Training loss (for one batch) at step 0: 0.5240\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2994\n",
            "Training loss (for one batch) at step 0: 0.5251\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2995\n",
            "Training loss (for one batch) at step 0: 0.5237\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2996\n",
            "Training loss (for one batch) at step 0: 0.5231\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2997\n",
            "Training loss (for one batch) at step 0: 0.5261\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2998\n",
            "Training loss (for one batch) at step 0: 0.5249\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 2999\n",
            "Training loss (for one batch) at step 0: 0.5275\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3000\n",
            "Training loss (for one batch) at step 0: 0.5257\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3001\n",
            "Training loss (for one batch) at step 0: 0.5322\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3002\n",
            "Training loss (for one batch) at step 0: 0.5320\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3003\n",
            "Training loss (for one batch) at step 0: 0.5323\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3004\n",
            "Training loss (for one batch) at step 0: 0.5339\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3005\n",
            "Training loss (for one batch) at step 0: 0.5391\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3006\n",
            "Training loss (for one batch) at step 0: 0.5430\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3007\n",
            "Training loss (for one batch) at step 0: 0.5404\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3008\n",
            "Training loss (for one batch) at step 0: 0.5428\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3009\n",
            "Training loss (for one batch) at step 0: 0.5510\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3010\n",
            "Training loss (for one batch) at step 0: 0.6412\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3011\n",
            "Training loss (for one batch) at step 0: 0.7061\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3012\n",
            "Training loss (for one batch) at step 0: 0.6723\n",
            "Accuracy (for one batch) at step 0: 0.0333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3013\n",
            "Training loss (for one batch) at step 0: 0.6591\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3014\n",
            "Training loss (for one batch) at step 0: 0.6893\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3015\n",
            "Training loss (for one batch) at step 0: 0.6437\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3016\n",
            "Training loss (for one batch) at step 0: 0.6510\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3017\n",
            "Training loss (for one batch) at step 0: 0.6455\n",
            "Accuracy (for one batch) at step 0: 0.0444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3018\n",
            "Training loss (for one batch) at step 0: 0.6278\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3019\n",
            "Training loss (for one batch) at step 0: 0.6250\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3020\n",
            "Training loss (for one batch) at step 0: 0.6613\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3021\n",
            "Training loss (for one batch) at step 0: 0.6252\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3022\n",
            "Training loss (for one batch) at step 0: 0.7493\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3023\n",
            "Training loss (for one batch) at step 0: 0.7828\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3024\n",
            "Training loss (for one batch) at step 0: 0.6272\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3025\n",
            "Training loss (for one batch) at step 0: 0.6344\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3026\n",
            "Training loss (for one batch) at step 0: 0.6301\n",
            "Accuracy (for one batch) at step 0: 0.0444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3027\n",
            "Training loss (for one batch) at step 0: 0.6242\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3028\n",
            "Training loss (for one batch) at step 0: 0.5933\n",
            "Accuracy (for one batch) at step 0: 0.0444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3029\n",
            "Training loss (for one batch) at step 0: 0.5747\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3030\n",
            "Training loss (for one batch) at step 0: 0.5660\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3031\n",
            "Training loss (for one batch) at step 0: 0.5519\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3032\n",
            "Training loss (for one batch) at step 0: 0.5535\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3033\n",
            "Training loss (for one batch) at step 0: 0.5460\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3034\n",
            "Training loss (for one batch) at step 0: 0.5426\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3035\n",
            "Training loss (for one batch) at step 0: 0.5407\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3036\n",
            "Training loss (for one batch) at step 0: 0.5391\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3037\n",
            "Training loss (for one batch) at step 0: 0.5343\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3038\n",
            "Training loss (for one batch) at step 0: 0.5315\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3039\n",
            "Training loss (for one batch) at step 0: 0.5294\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3040\n",
            "Training loss (for one batch) at step 0: 0.5257\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3041\n",
            "Training loss (for one batch) at step 0: 0.5244\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3042\n",
            "Training loss (for one batch) at step 0: 0.5262\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3043\n",
            "Training loss (for one batch) at step 0: 0.5231\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3044\n",
            "Training loss (for one batch) at step 0: 0.5265\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3045\n",
            "Training loss (for one batch) at step 0: 0.5261\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3046\n",
            "Training loss (for one batch) at step 0: 0.5284\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3047\n",
            "Training loss (for one batch) at step 0: 0.5294\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3048\n",
            "Training loss (for one batch) at step 0: 0.5300\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3049\n",
            "Training loss (for one batch) at step 0: 0.5320\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3050\n",
            "Training loss (for one batch) at step 0: 0.5324\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3051\n",
            "Training loss (for one batch) at step 0: 0.5321\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3052\n",
            "Training loss (for one batch) at step 0: 0.5347\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3053\n",
            "Training loss (for one batch) at step 0: 0.5293\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3054\n",
            "Training loss (for one batch) at step 0: 0.5325\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3055\n",
            "Training loss (for one batch) at step 0: 0.5384\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3056\n",
            "Training loss (for one batch) at step 0: 0.5342\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3057\n",
            "Training loss (for one batch) at step 0: 0.5258\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3058\n",
            "Training loss (for one batch) at step 0: 0.5287\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3059\n",
            "Training loss (for one batch) at step 0: 0.5259\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3060\n",
            "Training loss (for one batch) at step 0: 0.5251\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3061\n",
            "Training loss (for one batch) at step 0: 0.5213\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3062\n",
            "Training loss (for one batch) at step 0: 0.5228\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3063\n",
            "Training loss (for one batch) at step 0: 0.5176\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3064\n",
            "Training loss (for one batch) at step 0: 0.5182\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3065\n",
            "Training loss (for one batch) at step 0: 0.5156\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3066\n",
            "Training loss (for one batch) at step 0: 0.5160\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3067\n",
            "Training loss (for one batch) at step 0: 0.5154\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3068\n",
            "Training loss (for one batch) at step 0: 0.5121\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3069\n",
            "Training loss (for one batch) at step 0: 0.5124\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3070\n",
            "Training loss (for one batch) at step 0: 0.5103\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3071\n",
            "Training loss (for one batch) at step 0: 0.5110\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3072\n",
            "Training loss (for one batch) at step 0: 0.5093\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3073\n",
            "Training loss (for one batch) at step 0: 0.5096\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3074\n",
            "Training loss (for one batch) at step 0: 0.5096\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3075\n",
            "Training loss (for one batch) at step 0: 0.5116\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3076\n",
            "Training loss (for one batch) at step 0: 0.5097\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3077\n",
            "Training loss (for one batch) at step 0: 0.5130\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3078\n",
            "Training loss (for one batch) at step 0: 0.5104\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3079\n",
            "Training loss (for one batch) at step 0: 0.5129\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3080\n",
            "Training loss (for one batch) at step 0: 0.5136\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3081\n",
            "Training loss (for one batch) at step 0: 0.5146\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3082\n",
            "Training loss (for one batch) at step 0: 0.5151\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3083\n",
            "Training loss (for one batch) at step 0: 0.5171\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3084\n",
            "Training loss (for one batch) at step 0: 0.5176\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3085\n",
            "Training loss (for one batch) at step 0: 0.5272\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3086\n",
            "Training loss (for one batch) at step 0: 0.5316\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3087\n",
            "Training loss (for one batch) at step 0: 0.5426\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3088\n",
            "Training loss (for one batch) at step 0: 0.5626\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3089\n",
            "Training loss (for one batch) at step 0: 0.5535\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3090\n",
            "Training loss (for one batch) at step 0: 0.6692\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3091\n",
            "Training loss (for one batch) at step 0: 0.7268\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3092\n",
            "Training loss (for one batch) at step 0: 0.7825\n",
            "Accuracy (for one batch) at step 0: 0.0333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3093\n",
            "Training loss (for one batch) at step 0: 0.7213\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3094\n",
            "Training loss (for one batch) at step 0: 0.6945\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3095\n",
            "Training loss (for one batch) at step 0: 0.6796\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3096\n",
            "Training loss (for one batch) at step 0: 0.6758\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3097\n",
            "Training loss (for one batch) at step 0: 0.6375\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3098\n",
            "Training loss (for one batch) at step 0: 0.6872\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3099\n",
            "Training loss (for one batch) at step 0: 0.6637\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3100\n",
            "Training loss (for one batch) at step 0: 0.7122\n",
            "Accuracy (for one batch) at step 0: 0.0333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3101\n",
            "Training loss (for one batch) at step 0: 0.6811\n",
            "Accuracy (for one batch) at step 0: 0.0333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3102\n",
            "Training loss (for one batch) at step 0: 0.7167\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3103\n",
            "Training loss (for one batch) at step 0: 0.6683\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3104\n",
            "Training loss (for one batch) at step 0: 0.6511\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3105\n",
            "Training loss (for one batch) at step 0: 0.6228\n",
            "Accuracy (for one batch) at step 0: 0.0444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3106\n",
            "Training loss (for one batch) at step 0: 0.6046\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3107\n",
            "Training loss (for one batch) at step 0: 0.5874\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3108\n",
            "Training loss (for one batch) at step 0: 0.5850\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3109\n",
            "Training loss (for one batch) at step 0: 0.5629\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3110\n",
            "Training loss (for one batch) at step 0: 0.5756\n",
            "Accuracy (for one batch) at step 0: 0.0444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3111\n",
            "Training loss (for one batch) at step 0: 0.5877\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3112\n",
            "Training loss (for one batch) at step 0: 0.5533\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3113\n",
            "Training loss (for one batch) at step 0: 0.5597\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3114\n",
            "Training loss (for one batch) at step 0: 0.5492\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3115\n",
            "Training loss (for one batch) at step 0: 0.5555\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3116\n",
            "Training loss (for one batch) at step 0: 0.5484\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3117\n",
            "Training loss (for one batch) at step 0: 0.5419\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3118\n",
            "Training loss (for one batch) at step 0: 0.5359\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3119\n",
            "Training loss (for one batch) at step 0: 0.5325\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3120\n",
            "Training loss (for one batch) at step 0: 0.5345\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3121\n",
            "Training loss (for one batch) at step 0: 0.5396\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3122\n",
            "Training loss (for one batch) at step 0: 0.5306\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3123\n",
            "Training loss (for one batch) at step 0: 0.5277\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3124\n",
            "Training loss (for one batch) at step 0: 0.5201\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3125\n",
            "Training loss (for one batch) at step 0: 0.5205\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3126\n",
            "Training loss (for one batch) at step 0: 0.5164\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3127\n",
            "Training loss (for one batch) at step 0: 0.5096\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3128\n",
            "Training loss (for one batch) at step 0: 0.5149\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3129\n",
            "Training loss (for one batch) at step 0: 0.5102\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3130\n",
            "Training loss (for one batch) at step 0: 0.5117\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3131\n",
            "Training loss (for one batch) at step 0: 0.5079\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3132\n",
            "Training loss (for one batch) at step 0: 0.5089\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3133\n",
            "Training loss (for one batch) at step 0: 0.5077\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3134\n",
            "Training loss (for one batch) at step 0: 0.5068\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3135\n",
            "Training loss (for one batch) at step 0: 0.5064\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3136\n",
            "Training loss (for one batch) at step 0: 0.5062\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3137\n",
            "Training loss (for one batch) at step 0: 0.5064\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3138\n",
            "Training loss (for one batch) at step 0: 0.5065\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3139\n",
            "Training loss (for one batch) at step 0: 0.5077\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3140\n",
            "Training loss (for one batch) at step 0: 0.5114\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3141\n",
            "Training loss (for one batch) at step 0: 0.5107\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3142\n",
            "Training loss (for one batch) at step 0: 0.5193\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3143\n",
            "Training loss (for one batch) at step 0: 0.5231\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3144\n",
            "Training loss (for one batch) at step 0: 0.5291\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3145\n",
            "Training loss (for one batch) at step 0: 0.5540\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3146\n",
            "Training loss (for one batch) at step 0: 0.5538\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3147\n",
            "Training loss (for one batch) at step 0: 0.5375\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3148\n",
            "Training loss (for one batch) at step 0: 0.5312\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3149\n",
            "Training loss (for one batch) at step 0: 0.5251\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3150\n",
            "Training loss (for one batch) at step 0: 0.5219\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3151\n",
            "Training loss (for one batch) at step 0: 0.5181\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3152\n",
            "Training loss (for one batch) at step 0: 0.5119\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3153\n",
            "Training loss (for one batch) at step 0: 0.5102\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3154\n",
            "Training loss (for one batch) at step 0: 0.5067\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3155\n",
            "Training loss (for one batch) at step 0: 0.5011\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3156\n",
            "Training loss (for one batch) at step 0: 0.4992\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3157\n",
            "Training loss (for one batch) at step 0: 0.5010\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3158\n",
            "Training loss (for one batch) at step 0: 0.4967\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3159\n",
            "Training loss (for one batch) at step 0: 0.4979\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3160\n",
            "Training loss (for one batch) at step 0: 0.4976\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3161\n",
            "Training loss (for one batch) at step 0: 0.4947\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3162\n",
            "Training loss (for one batch) at step 0: 0.4945\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3163\n",
            "Training loss (for one batch) at step 0: 0.4968\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3164\n",
            "Training loss (for one batch) at step 0: 0.4966\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3165\n",
            "Training loss (for one batch) at step 0: 0.4974\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3166\n",
            "Training loss (for one batch) at step 0: 0.4987\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3167\n",
            "Training loss (for one batch) at step 0: 0.5022\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3168\n",
            "Training loss (for one batch) at step 0: 0.5032\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3169\n",
            "Training loss (for one batch) at step 0: 0.5085\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3170\n",
            "Training loss (for one batch) at step 0: 0.5040\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3171\n",
            "Training loss (for one batch) at step 0: 0.5012\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3172\n",
            "Training loss (for one batch) at step 0: 0.5012\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3173\n",
            "Training loss (for one batch) at step 0: 0.4957\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3174\n",
            "Training loss (for one batch) at step 0: 0.4952\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3175\n",
            "Training loss (for one batch) at step 0: 0.4924\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3176\n",
            "Training loss (for one batch) at step 0: 0.4927\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3177\n",
            "Training loss (for one batch) at step 0: 0.4896\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3178\n",
            "Training loss (for one batch) at step 0: 0.4886\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3179\n",
            "Training loss (for one batch) at step 0: 0.4864\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3180\n",
            "Training loss (for one batch) at step 0: 0.4854\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3181\n",
            "Training loss (for one batch) at step 0: 0.4835\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3182\n",
            "Training loss (for one batch) at step 0: 0.4836\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3183\n",
            "Training loss (for one batch) at step 0: 0.4821\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3184\n",
            "Training loss (for one batch) at step 0: 0.4808\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3185\n",
            "Training loss (for one batch) at step 0: 0.4805\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3186\n",
            "Training loss (for one batch) at step 0: 0.4804\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3187\n",
            "Training loss (for one batch) at step 0: 0.4820\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3188\n",
            "Training loss (for one batch) at step 0: 0.4792\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3189\n",
            "Training loss (for one batch) at step 0: 0.4794\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3190\n",
            "Training loss (for one batch) at step 0: 0.4817\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3191\n",
            "Training loss (for one batch) at step 0: 0.4858\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3192\n",
            "Training loss (for one batch) at step 0: 0.4882\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3193\n",
            "Training loss (for one batch) at step 0: 0.4996\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3194\n",
            "Training loss (for one batch) at step 0: 0.4873\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3195\n",
            "Training loss (for one batch) at step 0: 0.4877\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3196\n",
            "Training loss (for one batch) at step 0: 0.4855\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3197\n",
            "Training loss (for one batch) at step 0: 0.4833\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3198\n",
            "Training loss (for one batch) at step 0: 0.4892\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3199\n",
            "Training loss (for one batch) at step 0: 0.4833\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3200\n",
            "Training loss (for one batch) at step 0: 0.4825\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3201\n",
            "Training loss (for one batch) at step 0: 0.4855\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3202\n",
            "Training loss (for one batch) at step 0: 0.4809\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3203\n",
            "Training loss (for one batch) at step 0: 0.4785\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3204\n",
            "Training loss (for one batch) at step 0: 0.4753\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3205\n",
            "Training loss (for one batch) at step 0: 0.4790\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3206\n",
            "Training loss (for one batch) at step 0: 0.4738\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3207\n",
            "Training loss (for one batch) at step 0: 0.4736\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3208\n",
            "Training loss (for one batch) at step 0: 0.4715\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3209\n",
            "Training loss (for one batch) at step 0: 0.4692\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3210\n",
            "Training loss (for one batch) at step 0: 0.4696\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3211\n",
            "Training loss (for one batch) at step 0: 0.4778\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3212\n",
            "Training loss (for one batch) at step 0: 0.4802\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3213\n",
            "Training loss (for one batch) at step 0: 0.5045\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3214\n",
            "Training loss (for one batch) at step 0: 0.5127\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3215\n",
            "Training loss (for one batch) at step 0: 0.5388\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3216\n",
            "Training loss (for one batch) at step 0: 0.5129\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3217\n",
            "Training loss (for one batch) at step 0: 0.5232\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3218\n",
            "Training loss (for one batch) at step 0: 0.6412\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3219\n",
            "Training loss (for one batch) at step 0: 0.7937\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3220\n",
            "Training loss (for one batch) at step 0: 0.9583\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3221\n",
            "Training loss (for one batch) at step 0: 1.0109\n",
            "Accuracy (for one batch) at step 0: 0.0444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3222\n",
            "Training loss (for one batch) at step 0: 1.0498\n",
            "Accuracy (for one batch) at step 0: 0.0333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3223\n",
            "Training loss (for one batch) at step 0: 0.8742\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3224\n",
            "Training loss (for one batch) at step 0: 0.8888\n",
            "Accuracy (for one batch) at step 0: 0.0222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3225\n",
            "Training loss (for one batch) at step 0: 0.9249\n",
            "Accuracy (for one batch) at step 0: 0.0222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3226\n",
            "Training loss (for one batch) at step 0: 0.7662\n",
            "Accuracy (for one batch) at step 0: 0.0222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3227\n",
            "Training loss (for one batch) at step 0: 0.7528\n",
            "Accuracy (for one batch) at step 0: 0.0333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3228\n",
            "Training loss (for one batch) at step 0: 0.7543\n",
            "Accuracy (for one batch) at step 0: 0.0111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3229\n",
            "Training loss (for one batch) at step 0: 0.7370\n",
            "Accuracy (for one batch) at step 0: 0.0333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3230\n",
            "Training loss (for one batch) at step 0: 0.6676\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3231\n",
            "Training loss (for one batch) at step 0: 0.6352\n",
            "Accuracy (for one batch) at step 0: 0.0444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3232\n",
            "Training loss (for one batch) at step 0: 0.6212\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3233\n",
            "Training loss (for one batch) at step 0: 0.5724\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3234\n",
            "Training loss (for one batch) at step 0: 0.5485\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3235\n",
            "Training loss (for one batch) at step 0: 0.5447\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3236\n",
            "Training loss (for one batch) at step 0: 0.5297\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3237\n",
            "Training loss (for one batch) at step 0: 0.5198\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3238\n",
            "Training loss (for one batch) at step 0: 0.5113\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3239\n",
            "Training loss (for one batch) at step 0: 0.5025\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3240\n",
            "Training loss (for one batch) at step 0: 0.4987\n",
            "Accuracy (for one batch) at step 0: 0.1667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3241\n",
            "Training loss (for one batch) at step 0: 0.4927\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3242\n",
            "Training loss (for one batch) at step 0: 0.4895\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3243\n",
            "Training loss (for one batch) at step 0: 0.4873\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3244\n",
            "Training loss (for one batch) at step 0: 0.4844\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3245\n",
            "Training loss (for one batch) at step 0: 0.4824\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3246\n",
            "Training loss (for one batch) at step 0: 0.4811\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3247\n",
            "Training loss (for one batch) at step 0: 0.4790\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3248\n",
            "Training loss (for one batch) at step 0: 0.4771\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3249\n",
            "Training loss (for one batch) at step 0: 0.4764\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3250\n",
            "Training loss (for one batch) at step 0: 0.4753\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3251\n",
            "Training loss (for one batch) at step 0: 0.4737\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3252\n",
            "Training loss (for one batch) at step 0: 0.4724\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3253\n",
            "Training loss (for one batch) at step 0: 0.4716\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3254\n",
            "Training loss (for one batch) at step 0: 0.4700\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3255\n",
            "Training loss (for one batch) at step 0: 0.4686\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3256\n",
            "Training loss (for one batch) at step 0: 0.4674\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3257\n",
            "Training loss (for one batch) at step 0: 0.4693\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3258\n",
            "Training loss (for one batch) at step 0: 0.4674\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3259\n",
            "Training loss (for one batch) at step 0: 0.4672\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3260\n",
            "Training loss (for one batch) at step 0: 0.4672\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3261\n",
            "Training loss (for one batch) at step 0: 0.4743\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3262\n",
            "Training loss (for one batch) at step 0: 0.4715\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3263\n",
            "Training loss (for one batch) at step 0: 0.4737\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3264\n",
            "Training loss (for one batch) at step 0: 0.4773\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3265\n",
            "Training loss (for one batch) at step 0: 0.4850\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3266\n",
            "Training loss (for one batch) at step 0: 0.4837\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3267\n",
            "Training loss (for one batch) at step 0: 0.5077\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3268\n",
            "Training loss (for one batch) at step 0: 0.5025\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3269\n",
            "Training loss (for one batch) at step 0: 0.5229\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3270\n",
            "Training loss (for one batch) at step 0: 0.4934\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3271\n",
            "Training loss (for one batch) at step 0: 0.4993\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3272\n",
            "Training loss (for one batch) at step 0: 0.4985\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3273\n",
            "Training loss (for one batch) at step 0: 0.4962\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3274\n",
            "Training loss (for one batch) at step 0: 0.4954\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3275\n",
            "Training loss (for one batch) at step 0: 0.4857\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3276\n",
            "Training loss (for one batch) at step 0: 0.4925\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3277\n",
            "Training loss (for one batch) at step 0: 0.4889\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3278\n",
            "Training loss (for one batch) at step 0: 0.4756\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3279\n",
            "Training loss (for one batch) at step 0: 0.4728\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3280\n",
            "Training loss (for one batch) at step 0: 0.4714\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3281\n",
            "Training loss (for one batch) at step 0: 0.4649\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3282\n",
            "Training loss (for one batch) at step 0: 0.4623\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3283\n",
            "Training loss (for one batch) at step 0: 0.4632\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3284\n",
            "Training loss (for one batch) at step 0: 0.4586\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3285\n",
            "Training loss (for one batch) at step 0: 0.4581\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3286\n",
            "Training loss (for one batch) at step 0: 0.4564\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3287\n",
            "Training loss (for one batch) at step 0: 0.4547\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3288\n",
            "Training loss (for one batch) at step 0: 0.4544\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3289\n",
            "Training loss (for one batch) at step 0: 0.4528\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3290\n",
            "Training loss (for one batch) at step 0: 0.4520\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3291\n",
            "Training loss (for one batch) at step 0: 0.4514\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3292\n",
            "Training loss (for one batch) at step 0: 0.4504\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3293\n",
            "Training loss (for one batch) at step 0: 0.4506\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3294\n",
            "Training loss (for one batch) at step 0: 0.4506\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3295\n",
            "Training loss (for one batch) at step 0: 0.4500\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3296\n",
            "Training loss (for one batch) at step 0: 0.4487\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3297\n",
            "Training loss (for one batch) at step 0: 0.4485\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3298\n",
            "Training loss (for one batch) at step 0: 0.4479\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3299\n",
            "Training loss (for one batch) at step 0: 0.4490\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3300\n",
            "Training loss (for one batch) at step 0: 0.4488\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3301\n",
            "Training loss (for one batch) at step 0: 0.4478\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3302\n",
            "Training loss (for one batch) at step 0: 0.4519\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3303\n",
            "Training loss (for one batch) at step 0: 0.4504\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3304\n",
            "Training loss (for one batch) at step 0: 0.4483\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3305\n",
            "Training loss (for one batch) at step 0: 0.4505\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3306\n",
            "Training loss (for one batch) at step 0: 0.4494\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3307\n",
            "Training loss (for one batch) at step 0: 0.4468\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3308\n",
            "Training loss (for one batch) at step 0: 0.4482\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3309\n",
            "Training loss (for one batch) at step 0: 0.4475\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3310\n",
            "Training loss (for one batch) at step 0: 0.4481\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3311\n",
            "Training loss (for one batch) at step 0: 0.4501\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3312\n",
            "Training loss (for one batch) at step 0: 0.4486\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3313\n",
            "Training loss (for one batch) at step 0: 0.4460\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3314\n",
            "Training loss (for one batch) at step 0: 0.4467\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3315\n",
            "Training loss (for one batch) at step 0: 0.4456\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3316\n",
            "Training loss (for one batch) at step 0: 0.4448\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3317\n",
            "Training loss (for one batch) at step 0: 0.4471\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3318\n",
            "Training loss (for one batch) at step 0: 0.4457\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3319\n",
            "Training loss (for one batch) at step 0: 0.4438\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3320\n",
            "Training loss (for one batch) at step 0: 0.4443\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3321\n",
            "Training loss (for one batch) at step 0: 0.4430\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3322\n",
            "Training loss (for one batch) at step 0: 0.4442\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3323\n",
            "Training loss (for one batch) at step 0: 0.4448\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3324\n",
            "Training loss (for one batch) at step 0: 0.4445\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3325\n",
            "Training loss (for one batch) at step 0: 0.4446\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3326\n",
            "Training loss (for one batch) at step 0: 0.4663\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3327\n",
            "Training loss (for one batch) at step 0: 0.4781\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3328\n",
            "Training loss (for one batch) at step 0: 0.5919\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3329\n",
            "Training loss (for one batch) at step 0: 0.6175\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3330\n",
            "Training loss (for one batch) at step 0: 0.5422\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3331\n",
            "Training loss (for one batch) at step 0: 0.5241\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3332\n",
            "Training loss (for one batch) at step 0: 0.5669\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3333\n",
            "Training loss (for one batch) at step 0: 0.5193\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3334\n",
            "Training loss (for one batch) at step 0: 0.7680\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3335\n",
            "Training loss (for one batch) at step 0: 0.8520\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3336\n",
            "Training loss (for one batch) at step 0: 1.2482\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3337\n",
            "Training loss (for one batch) at step 0: 1.0858\n",
            "Accuracy (for one batch) at step 0: 0.0333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3338\n",
            "Training loss (for one batch) at step 0: 1.1720\n",
            "Accuracy (for one batch) at step 0: 0.0222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3339\n",
            "Training loss (for one batch) at step 0: 1.0026\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3340\n",
            "Training loss (for one batch) at step 0: 0.9078\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3341\n",
            "Training loss (for one batch) at step 0: 0.8146\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3342\n",
            "Training loss (for one batch) at step 0: 0.7093\n",
            "Accuracy (for one batch) at step 0: 0.0222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3343\n",
            "Training loss (for one batch) at step 0: 0.6501\n",
            "Accuracy (for one batch) at step 0: 0.0222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3344\n",
            "Training loss (for one batch) at step 0: 0.8878\n",
            "Accuracy (for one batch) at step 0: 0.0444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3345\n",
            "Training loss (for one batch) at step 0: 1.1687\n",
            "Accuracy (for one batch) at step 0: 0.0111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3346\n",
            "Training loss (for one batch) at step 0: 0.9094\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3347\n",
            "Training loss (for one batch) at step 0: 0.9743\n",
            "Accuracy (for one batch) at step 0: 0.0444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3348\n",
            "Training loss (for one batch) at step 0: 0.6988\n",
            "Accuracy (for one batch) at step 0: 0.0333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3349\n",
            "Training loss (for one batch) at step 0: 0.6623\n",
            "Accuracy (for one batch) at step 0: 0.0556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3350\n",
            "Training loss (for one batch) at step 0: 0.6774\n",
            "Accuracy (for one batch) at step 0: 0.0333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3351\n",
            "Training loss (for one batch) at step 0: 0.6514\n",
            "Accuracy (for one batch) at step 0: 0.0222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3352\n",
            "Training loss (for one batch) at step 0: 0.5963\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3353\n",
            "Training loss (for one batch) at step 0: 0.5553\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3354\n",
            "Training loss (for one batch) at step 0: 0.5728\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3355\n",
            "Training loss (for one batch) at step 0: 0.5771\n",
            "Accuracy (for one batch) at step 0: 0.0778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3356\n",
            "Training loss (for one batch) at step 0: 0.5362\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3357\n",
            "Training loss (for one batch) at step 0: 0.5250\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3358\n",
            "Training loss (for one batch) at step 0: 0.5220\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3359\n",
            "Training loss (for one batch) at step 0: 0.4928\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3360\n",
            "Training loss (for one batch) at step 0: 0.4908\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3361\n",
            "Training loss (for one batch) at step 0: 0.4835\n",
            "Accuracy (for one batch) at step 0: 0.1667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3362\n",
            "Training loss (for one batch) at step 0: 0.4833\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3363\n",
            "Training loss (for one batch) at step 0: 0.4727\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3364\n",
            "Training loss (for one batch) at step 0: 0.4649\n",
            "Accuracy (for one batch) at step 0: 0.1667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3365\n",
            "Training loss (for one batch) at step 0: 0.4769\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3366\n",
            "Training loss (for one batch) at step 0: 0.4802\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3367\n",
            "Training loss (for one batch) at step 0: 0.4870\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3368\n",
            "Training loss (for one batch) at step 0: 0.4926\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3369\n",
            "Training loss (for one batch) at step 0: 0.4755\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3370\n",
            "Training loss (for one batch) at step 0: 0.4706\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3371\n",
            "Training loss (for one batch) at step 0: 0.4649\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3372\n",
            "Training loss (for one batch) at step 0: 0.4706\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3373\n",
            "Training loss (for one batch) at step 0: 0.4592\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3374\n",
            "Training loss (for one batch) at step 0: 0.4656\n",
            "Accuracy (for one batch) at step 0: 0.1667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3375\n",
            "Training loss (for one batch) at step 0: 0.4545\n",
            "Accuracy (for one batch) at step 0: 0.1667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3376\n",
            "Training loss (for one batch) at step 0: 0.4549\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3377\n",
            "Training loss (for one batch) at step 0: 0.4493\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3378\n",
            "Training loss (for one batch) at step 0: 0.4527\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3379\n",
            "Training loss (for one batch) at step 0: 0.4500\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3380\n",
            "Training loss (for one batch) at step 0: 0.4464\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3381\n",
            "Training loss (for one batch) at step 0: 0.4441\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3382\n",
            "Training loss (for one batch) at step 0: 0.4426\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3383\n",
            "Training loss (for one batch) at step 0: 0.4427\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3384\n",
            "Training loss (for one batch) at step 0: 0.4417\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3385\n",
            "Training loss (for one batch) at step 0: 0.4418\n",
            "Accuracy (for one batch) at step 0: 0.1778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3386\n",
            "Training loss (for one batch) at step 0: 0.4410\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3387\n",
            "Training loss (for one batch) at step 0: 0.4397\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3388\n",
            "Training loss (for one batch) at step 0: 0.4403\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3389\n",
            "Training loss (for one batch) at step 0: 0.4391\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3390\n",
            "Training loss (for one batch) at step 0: 0.4383\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3391\n",
            "Training loss (for one batch) at step 0: 0.4385\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3392\n",
            "Training loss (for one batch) at step 0: 0.4371\n",
            "Accuracy (for one batch) at step 0: 0.1667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3393\n",
            "Training loss (for one batch) at step 0: 0.4374\n",
            "Accuracy (for one batch) at step 0: 0.1667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3394\n",
            "Training loss (for one batch) at step 0: 0.4364\n",
            "Accuracy (for one batch) at step 0: 0.1667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3395\n",
            "Training loss (for one batch) at step 0: 0.4352\n",
            "Accuracy (for one batch) at step 0: 0.1667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3396\n",
            "Training loss (for one batch) at step 0: 0.4382\n",
            "Accuracy (for one batch) at step 0: 0.1667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3397\n",
            "Training loss (for one batch) at step 0: 0.4352\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3398\n",
            "Training loss (for one batch) at step 0: 0.4370\n",
            "Accuracy (for one batch) at step 0: 0.1667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3399\n",
            "Training loss (for one batch) at step 0: 0.4344\n",
            "Accuracy (for one batch) at step 0: 0.1667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3400\n",
            "Training loss (for one batch) at step 0: 0.4379\n",
            "Accuracy (for one batch) at step 0: 0.1667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3401\n",
            "Training loss (for one batch) at step 0: 0.4367\n",
            "Accuracy (for one batch) at step 0: 0.1667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3402\n",
            "Training loss (for one batch) at step 0: 0.4338\n",
            "Accuracy (for one batch) at step 0: 0.1667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3403\n",
            "Training loss (for one batch) at step 0: 0.4353\n",
            "Accuracy (for one batch) at step 0: 0.1667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3404\n",
            "Training loss (for one batch) at step 0: 0.4346\n",
            "Accuracy (for one batch) at step 0: 0.1667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3405\n",
            "Training loss (for one batch) at step 0: 0.4324\n",
            "Accuracy (for one batch) at step 0: 0.1667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3406\n",
            "Training loss (for one batch) at step 0: 0.4407\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3407\n",
            "Training loss (for one batch) at step 0: 0.4377\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3408\n",
            "Training loss (for one batch) at step 0: 0.4326\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3409\n",
            "Training loss (for one batch) at step 0: 0.4337\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3410\n",
            "Training loss (for one batch) at step 0: 0.4329\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3411\n",
            "Training loss (for one batch) at step 0: 0.4335\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3412\n",
            "Training loss (for one batch) at step 0: 0.4312\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3413\n",
            "Training loss (for one batch) at step 0: 0.4317\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3414\n",
            "Training loss (for one batch) at step 0: 0.4323\n",
            "Accuracy (for one batch) at step 0: 0.1667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3415\n",
            "Training loss (for one batch) at step 0: 0.4303\n",
            "Accuracy (for one batch) at step 0: 0.1667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3416\n",
            "Training loss (for one batch) at step 0: 0.4292\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3417\n",
            "Training loss (for one batch) at step 0: 0.4355\n",
            "Accuracy (for one batch) at step 0: 0.1778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3418\n",
            "Training loss (for one batch) at step 0: 0.4376\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3419\n",
            "Training loss (for one batch) at step 0: 0.4499\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3420\n",
            "Training loss (for one batch) at step 0: 0.4714\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3421\n",
            "Training loss (for one batch) at step 0: 0.4609\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3422\n",
            "Training loss (for one batch) at step 0: 0.4539\n",
            "Accuracy (for one batch) at step 0: 0.1889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3423\n",
            "Training loss (for one batch) at step 0: 0.4583\n",
            "Accuracy (for one batch) at step 0: 0.1778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3424\n",
            "Training loss (for one batch) at step 0: 0.4495\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3425\n",
            "Training loss (for one batch) at step 0: 0.4437\n",
            "Accuracy (for one batch) at step 0: 0.1667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3426\n",
            "Training loss (for one batch) at step 0: 0.4529\n",
            "Accuracy (for one batch) at step 0: 0.1667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3427\n",
            "Training loss (for one batch) at step 0: 0.4514\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3428\n",
            "Training loss (for one batch) at step 0: 0.4587\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3429\n",
            "Training loss (for one batch) at step 0: 0.4401\n",
            "Accuracy (for one batch) at step 0: 0.1778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3430\n",
            "Training loss (for one batch) at step 0: 0.4842\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3431\n",
            "Training loss (for one batch) at step 0: 0.4647\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3432\n",
            "Training loss (for one batch) at step 0: 0.5119\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3433\n",
            "Training loss (for one batch) at step 0: 0.6002\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3434\n",
            "Training loss (for one batch) at step 0: 0.5406\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3435\n",
            "Training loss (for one batch) at step 0: 0.5558\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3436\n",
            "Training loss (for one batch) at step 0: 0.6077\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3437\n",
            "Training loss (for one batch) at step 0: 0.5644\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3438\n",
            "Training loss (for one batch) at step 0: 0.5312\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3439\n",
            "Training loss (for one batch) at step 0: 0.5077\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3440\n",
            "Training loss (for one batch) at step 0: 0.5544\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3441\n",
            "Training loss (for one batch) at step 0: 0.6048\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3442\n",
            "Training loss (for one batch) at step 0: 0.5557\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3443\n",
            "Training loss (for one batch) at step 0: 0.5853\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3444\n",
            "Training loss (for one batch) at step 0: 0.5285\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3445\n",
            "Training loss (for one batch) at step 0: 0.5340\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3446\n",
            "Training loss (for one batch) at step 0: 0.5084\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3447\n",
            "Training loss (for one batch) at step 0: 0.4774\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3448\n",
            "Training loss (for one batch) at step 0: 0.4813\n",
            "Accuracy (for one batch) at step 0: 0.1778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3449\n",
            "Training loss (for one batch) at step 0: 0.4606\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3450\n",
            "Training loss (for one batch) at step 0: 0.4651\n",
            "Accuracy (for one batch) at step 0: 0.1778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3451\n",
            "Training loss (for one batch) at step 0: 0.4587\n",
            "Accuracy (for one batch) at step 0: 0.1778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3452\n",
            "Training loss (for one batch) at step 0: 0.4539\n",
            "Accuracy (for one batch) at step 0: 0.1889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3453\n",
            "Training loss (for one batch) at step 0: 0.4475\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3454\n",
            "Training loss (for one batch) at step 0: 0.4484\n",
            "Accuracy (for one batch) at step 0: 0.1778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3455\n",
            "Training loss (for one batch) at step 0: 0.4465\n",
            "Accuracy (for one batch) at step 0: 0.1778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3456\n",
            "Training loss (for one batch) at step 0: 0.4367\n",
            "Accuracy (for one batch) at step 0: 0.1889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3457\n",
            "Training loss (for one batch) at step 0: 0.4466\n",
            "Accuracy (for one batch) at step 0: 0.2000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3458\n",
            "Training loss (for one batch) at step 0: 0.4335\n",
            "Accuracy (for one batch) at step 0: 0.1667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3459\n",
            "Training loss (for one batch) at step 0: 0.4409\n",
            "Accuracy (for one batch) at step 0: 0.1889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3460\n",
            "Training loss (for one batch) at step 0: 0.4387\n",
            "Accuracy (for one batch) at step 0: 0.1889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3461\n",
            "Training loss (for one batch) at step 0: 0.4658\n",
            "Accuracy (for one batch) at step 0: 0.1667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3462\n",
            "Training loss (for one batch) at step 0: 0.4604\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3463\n",
            "Training loss (for one batch) at step 0: 0.4414\n",
            "Accuracy (for one batch) at step 0: 0.1667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3464\n",
            "Training loss (for one batch) at step 0: 0.4440\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3465\n",
            "Training loss (for one batch) at step 0: 0.4385\n",
            "Accuracy (for one batch) at step 0: 0.1889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3466\n",
            "Training loss (for one batch) at step 0: 0.4366\n",
            "Accuracy (for one batch) at step 0: 0.1889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3467\n",
            "Training loss (for one batch) at step 0: 0.4367\n",
            "Accuracy (for one batch) at step 0: 0.2000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3468\n",
            "Training loss (for one batch) at step 0: 0.4363\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3469\n",
            "Training loss (for one batch) at step 0: 0.4306\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3470\n",
            "Training loss (for one batch) at step 0: 0.4354\n",
            "Accuracy (for one batch) at step 0: 0.1667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3471\n",
            "Training loss (for one batch) at step 0: 0.4337\n",
            "Accuracy (for one batch) at step 0: 0.1889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3472\n",
            "Training loss (for one batch) at step 0: 0.4419\n",
            "Accuracy (for one batch) at step 0: 0.1667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3473\n",
            "Training loss (for one batch) at step 0: 0.4337\n",
            "Accuracy (for one batch) at step 0: 0.1667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3474\n",
            "Training loss (for one batch) at step 0: 0.4458\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3475\n",
            "Training loss (for one batch) at step 0: 0.4473\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3476\n",
            "Training loss (for one batch) at step 0: 0.4443\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3477\n",
            "Training loss (for one batch) at step 0: 0.4433\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3478\n",
            "Training loss (for one batch) at step 0: 0.4541\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3479\n",
            "Training loss (for one batch) at step 0: 0.4447\n",
            "Accuracy (for one batch) at step 0: 0.1889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3480\n",
            "Training loss (for one batch) at step 0: 0.4560\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3481\n",
            "Training loss (for one batch) at step 0: 0.4572\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3482\n",
            "Training loss (for one batch) at step 0: 0.4484\n",
            "Accuracy (for one batch) at step 0: 0.1889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3483\n",
            "Training loss (for one batch) at step 0: 0.4465\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3484\n",
            "Training loss (for one batch) at step 0: 0.4454\n",
            "Accuracy (for one batch) at step 0: 0.1778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3485\n",
            "Training loss (for one batch) at step 0: 0.4382\n",
            "Accuracy (for one batch) at step 0: 0.1778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3486\n",
            "Training loss (for one batch) at step 0: 0.4302\n",
            "Accuracy (for one batch) at step 0: 0.1778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3487\n",
            "Training loss (for one batch) at step 0: 0.4287\n",
            "Accuracy (for one batch) at step 0: 0.1889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3488\n",
            "Training loss (for one batch) at step 0: 0.4271\n",
            "Accuracy (for one batch) at step 0: 0.2111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3489\n",
            "Training loss (for one batch) at step 0: 0.4272\n",
            "Accuracy (for one batch) at step 0: 0.1778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3490\n",
            "Training loss (for one batch) at step 0: 0.4239\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3491\n",
            "Training loss (for one batch) at step 0: 0.4263\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3492\n",
            "Training loss (for one batch) at step 0: 0.4248\n",
            "Accuracy (for one batch) at step 0: 0.1667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3493\n",
            "Training loss (for one batch) at step 0: 0.4246\n",
            "Accuracy (for one batch) at step 0: 0.1667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3494\n",
            "Training loss (for one batch) at step 0: 0.4210\n",
            "Accuracy (for one batch) at step 0: 0.1778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3495\n",
            "Training loss (for one batch) at step 0: 0.4332\n",
            "Accuracy (for one batch) at step 0: 0.1889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3496\n",
            "Training loss (for one batch) at step 0: 0.4354\n",
            "Accuracy (for one batch) at step 0: 0.2000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3497\n",
            "Training loss (for one batch) at step 0: 0.4271\n",
            "Accuracy (for one batch) at step 0: 0.1889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3498\n",
            "Training loss (for one batch) at step 0: 0.4245\n",
            "Accuracy (for one batch) at step 0: 0.1889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3499\n",
            "Training loss (for one batch) at step 0: 0.4239\n",
            "Accuracy (for one batch) at step 0: 0.1889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3500\n",
            "Training loss (for one batch) at step 0: 0.4223\n",
            "Accuracy (for one batch) at step 0: 0.1889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3501\n",
            "Training loss (for one batch) at step 0: 0.4215\n",
            "Accuracy (for one batch) at step 0: 0.2000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3502\n",
            "Training loss (for one batch) at step 0: 0.4331\n",
            "Accuracy (for one batch) at step 0: 0.1667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3503\n",
            "Training loss (for one batch) at step 0: 0.4482\n",
            "Accuracy (for one batch) at step 0: 0.1778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3504\n",
            "Training loss (for one batch) at step 0: 0.4398\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3505\n",
            "Training loss (for one batch) at step 0: 0.4369\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3506\n",
            "Training loss (for one batch) at step 0: 0.4406\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3507\n",
            "Training loss (for one batch) at step 0: 0.4408\n",
            "Accuracy (for one batch) at step 0: 0.1889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3508\n",
            "Training loss (for one batch) at step 0: 0.4358\n",
            "Accuracy (for one batch) at step 0: 0.1778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3509\n",
            "Training loss (for one batch) at step 0: 0.4267\n",
            "Accuracy (for one batch) at step 0: 0.1667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3510\n",
            "Training loss (for one batch) at step 0: 0.4276\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3511\n",
            "Training loss (for one batch) at step 0: 0.4281\n",
            "Accuracy (for one batch) at step 0: 0.2111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3512\n",
            "Training loss (for one batch) at step 0: 0.4266\n",
            "Accuracy (for one batch) at step 0: 0.1889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3513\n",
            "Training loss (for one batch) at step 0: 0.4199\n",
            "Accuracy (for one batch) at step 0: 0.2000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3514\n",
            "Training loss (for one batch) at step 0: 0.4186\n",
            "Accuracy (for one batch) at step 0: 0.1778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3515\n",
            "Training loss (for one batch) at step 0: 0.4170\n",
            "Accuracy (for one batch) at step 0: 0.1778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3516\n",
            "Training loss (for one batch) at step 0: 0.4152\n",
            "Accuracy (for one batch) at step 0: 0.1778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3517\n",
            "Training loss (for one batch) at step 0: 0.4149\n",
            "Accuracy (for one batch) at step 0: 0.1889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3518\n",
            "Training loss (for one batch) at step 0: 0.4142\n",
            "Accuracy (for one batch) at step 0: 0.1778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3519\n",
            "Training loss (for one batch) at step 0: 0.4137\n",
            "Accuracy (for one batch) at step 0: 0.1778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3520\n",
            "Training loss (for one batch) at step 0: 0.4146\n",
            "Accuracy (for one batch) at step 0: 0.2111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3521\n",
            "Training loss (for one batch) at step 0: 0.4137\n",
            "Accuracy (for one batch) at step 0: 0.1667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3522\n",
            "Training loss (for one batch) at step 0: 0.4122\n",
            "Accuracy (for one batch) at step 0: 0.2000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3523\n",
            "Training loss (for one batch) at step 0: 0.4124\n",
            "Accuracy (for one batch) at step 0: 0.1667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3524\n",
            "Training loss (for one batch) at step 0: 0.4106\n",
            "Accuracy (for one batch) at step 0: 0.1778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3525\n",
            "Training loss (for one batch) at step 0: 0.4105\n",
            "Accuracy (for one batch) at step 0: 0.1778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3526\n",
            "Training loss (for one batch) at step 0: 0.4110\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3527\n",
            "Training loss (for one batch) at step 0: 0.4109\n",
            "Accuracy (for one batch) at step 0: 0.1778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3528\n",
            "Training loss (for one batch) at step 0: 0.4148\n",
            "Accuracy (for one batch) at step 0: 0.2222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3529\n",
            "Training loss (for one batch) at step 0: 0.4123\n",
            "Accuracy (for one batch) at step 0: 0.1778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3530\n",
            "Training loss (for one batch) at step 0: 0.4097\n",
            "Accuracy (for one batch) at step 0: 0.1889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3531\n",
            "Training loss (for one batch) at step 0: 0.4084\n",
            "Accuracy (for one batch) at step 0: 0.1889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3532\n",
            "Training loss (for one batch) at step 0: 0.4065\n",
            "Accuracy (for one batch) at step 0: 0.1889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3533\n",
            "Training loss (for one batch) at step 0: 0.4101\n",
            "Accuracy (for one batch) at step 0: 0.1889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3534\n",
            "Training loss (for one batch) at step 0: 0.4299\n",
            "Accuracy (for one batch) at step 0: 0.1778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3535\n",
            "Training loss (for one batch) at step 0: 0.4662\n",
            "Accuracy (for one batch) at step 0: 0.1667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3536\n",
            "Training loss (for one batch) at step 0: 0.4773\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3537\n",
            "Training loss (for one batch) at step 0: 0.4707\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3538\n",
            "Training loss (for one batch) at step 0: 0.5722\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3539\n",
            "Training loss (for one batch) at step 0: 0.6149\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3540\n",
            "Training loss (for one batch) at step 0: 0.6150\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3541\n",
            "Training loss (for one batch) at step 0: 0.5452\n",
            "Accuracy (for one batch) at step 0: 0.1667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3542\n",
            "Training loss (for one batch) at step 0: 0.6086\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3543\n",
            "Training loss (for one batch) at step 0: 0.6048\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3544\n",
            "Training loss (for one batch) at step 0: 0.5556\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3545\n",
            "Training loss (for one batch) at step 0: 0.5468\n",
            "Accuracy (for one batch) at step 0: 0.1667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3546\n",
            "Training loss (for one batch) at step 0: 0.5915\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3547\n",
            "Training loss (for one batch) at step 0: 0.5576\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3548\n",
            "Training loss (for one batch) at step 0: 0.5331\n",
            "Accuracy (for one batch) at step 0: 0.0889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3549\n",
            "Training loss (for one batch) at step 0: 0.5070\n",
            "Accuracy (for one batch) at step 0: 0.1333\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3550\n",
            "Training loss (for one batch) at step 0: 0.5045\n",
            "Accuracy (for one batch) at step 0: 0.1889\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3551\n",
            "Training loss (for one batch) at step 0: 0.5661\n",
            "Accuracy (for one batch) at step 0: 0.1778\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3552\n",
            "Training loss (for one batch) at step 0: 0.5133\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3553\n",
            "Training loss (for one batch) at step 0: 0.5986\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3554\n",
            "Training loss (for one batch) at step 0: 0.5307\n",
            "Accuracy (for one batch) at step 0: 0.1222\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3555\n",
            "Training loss (for one batch) at step 0: 0.6246\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3556\n",
            "Training loss (for one batch) at step 0: 0.5537\n",
            "Accuracy (for one batch) at step 0: 0.1556\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3557\n",
            "Training loss (for one batch) at step 0: 0.5730\n",
            "Accuracy (for one batch) at step 0: 0.1000\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3558\n",
            "Training loss (for one batch) at step 0: 0.5780\n",
            "Accuracy (for one batch) at step 0: 0.1444\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3559\n",
            "Training loss (for one batch) at step 0: 0.6400\n",
            "Accuracy (for one batch) at step 0: 0.0667\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3560\n",
            "Training loss (for one batch) at step 0: 0.6415\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3561\n",
            "Training loss (for one batch) at step 0: 0.5879\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3562\n",
            "Training loss (for one batch) at step 0: 0.5391\n",
            "Accuracy (for one batch) at step 0: 0.1111\n",
            "Seen so far: 1 samples\n",
            "\n",
            "Start of epoch 3563\n",
            "Training loss (for one batch) at step 0: 0.4849\n",
            "Accuracy (for one batch) at step 0: 0.1889\n",
            "Seen so far: 1 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing"
      ],
      "metadata": {
        "id": "B41Tuvym_t--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l=[]\n",
        "for step, g in enumerate(md2):\n",
        "  loader_tr  = SingleLoader(MyDataset([g]))\n",
        "  l.append(loader_tr.__next__())"
      ],
      "metadata": {
        "id": "qEaXqi8DQkOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc=0\n",
        "running_loss = 0\n",
        "\n",
        "for step, g in enumerate(md2):\n",
        "    inputs, target = l[step]\n",
        "    # Open a GradientTape to record the operations run\n",
        "    # during the forward pass, which enables auto-differentiation.\n",
        "\n",
        "\n",
        "    logits,att = model(inputs, training=False)  # Logits for this minibatch\n",
        "    logits = logits[0:n_out]\n",
        "    # Compute the loss value for this minibatch.\n",
        "    loss_value = loss_fn(target, logits)\n",
        "    running_loss+=loss_value\n",
        "    acc += (tf.argmax(logits,1)==tf.reshape(target,-1)).numpy().sum()==len(tf.reshape(target,-1))\n",
        "\n",
        "print(\"f-loss\",running_loss/len(md2))\n",
        "print(\"f-acc\",acc/len(md2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ca7ATdUkQUcm",
        "outputId": "4daaba99-4551-454a-ad70-3930027aacf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f-loss tf.Tensor(0.15420513, shape=(), dtype=float32)\n",
            "f-acc 0.9666666666666667\n"
          ]
        }
      ]
    }
  ]
}